[
  {
    "id": 1,
    "moduleSlug": "testing-fundamentals",
    "title": "Introduction to Software Testing",
    "order": 1,
    "objectives": [
      "Understand the fundamental principles and importance of software testing",
      "Learn different types of software testing and when to apply them",
      "Identify the role of testing in the software development lifecycle",
      "Recognize common testing terminology and concepts"
    ],
    "intro": "Software testing is a critical practice in modern software development that ensures applications meet quality standards, function as expected, and provide value to users. Testing is not just about finding bugs; it's about building confidence in the software, reducing risks, and ensuring that applications behave correctly under various conditions.\n\nIn this lesson, you'll learn about the fundamental principles of software testing, including the testing pyramid which guides the distribution of different test types in a project. You'll understand why testing is essential for delivering reliable software and how it fits into different development methodologies like Agile and DevOps.\n\nYou'll explore the different levels of testing, from unit testing individual functions to integration testing component interactions, and system testing complete workflows. Each level serves a specific purpose and provides different types of feedback about the software's quality.\n\nThe lesson will also cover the psychology of testing, including the difference between developer and tester mindsets, and why independent testing is valuable. You'll learn about the principles of good testing, such as exhaustive testing being impossible, early testing being more effective, and defect clustering.\n\nBy mastering these fundamentals, you'll understand why testing is not a phase that happens at the end of development, but an ongoing activity that should be integrated throughout the entire development process.",
    "code": {
      "example": "// Example of a simple function that needs testing\npublic class Calculator\n{\n    public int Add(int a, int b)\n    {\n        return a + b;\n    }\n    \n    public double Divide(double dividend, double divisor)\n    {\n        if (divisor == 0)\n        {\n            throw new DivideByZeroException(\"Cannot divide by zero\");\n        }\n        return dividend / divisor;\n    }\n    \n    public bool IsEven(int number)\n    {\n        return number % 2 == 0;\n    }\n}\n\n// Without testing, how do we know this code works correctly?\n// What happens with negative numbers?\n// What about edge cases like int.MaxValue?\n\n// Example test scenarios that should be considered:\n// 1. Normal cases: Add(2, 3) should return 5\n// 2. Edge cases: Add(0, 0) should return 0\n// 3. Negative numbers: Add(-1, 1) should return 0\n// 4. Boundary values: Add(int.MaxValue, 0) should return int.MaxValue\n// 5. Error conditions: Divide(10, 0) should throw DivideByZeroException\n\n// Testing helps us verify all these scenarios work as expected\n// and gives us confidence when making changes to the code.",
      "explanation": "This example shows a simple Calculator class with basic mathematical operations. Without testing, we can't be certain the code works correctly in all scenarios. The comments illustrate various test cases that should be considered, including normal cases, edge cases, and error conditions. Testing provides confidence that our code behaves correctly and helps prevent regressions when changes are made.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Treating testing as a phase that happens only at the end of development",
        "solution": "Integrate testing throughout the development process with practices like Test-Driven Development (TDD)",
        "severity": "high"
      },
      {
        "mistake": "Writing tests that are too broad or too narrow in scope",
        "solution": "Follow the testing pyramid - many unit tests, fewer integration tests, and fewer end-to-end tests",
        "severity": "medium"
      },
      {
        "mistake": "Not considering edge cases and error conditions in tests",
        "solution": "Think about boundary values, null inputs, and unexpected user behavior when writing tests",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Identify Test Scenarios for a User Registration Function",
        "description": "Analyze a user registration function and identify comprehensive test scenarios.",
        "checkpoints": [
          "List normal test cases for valid user input",
          "Identify edge cases such as boundary values for input fields",
          "Consider error conditions like duplicate usernames or invalid email formats",
          "Think about security-related test scenarios",
          "Prioritize test cases based on risk and likelihood"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-2"
    ],
    "estimatedMinutes": 45,
    "difficulty": "Beginner",
    "tags": [
      "testing",
      "fundamentals",
      "principles",
      "SDLC"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 2,
    "moduleSlug": "testing-fundamentals",
    "title": "Unit Testing Principles",
    "order": 2,
    "objectives": [
      "Master the fundamentals of unit testing and its benefits",
      "Learn the FIRST principles for writing effective unit tests",
      "Understand how to structure unit tests using the Arrange-Act-Assert pattern",
      "Implement unit tests for isolated units of code"
    ],
    "intro": "Unit testing is the foundation of any comprehensive testing strategy. It involves testing individual units or components of software in isolation to ensure they function correctly. A unit is typically the smallest testable part of an application, such as a function, method, or class.\n\nEffective unit tests follow the FIRST principles: they should be Fast (run quickly), Independent (not depend on other tests), Repeatable (produce the same results), Self-validating (automatically determine pass/fail), and Thorough (cover important scenarios). These principles ensure that unit tests provide maximum value with minimal maintenance overhead.\n\nThe Arrange-Act-Assert (AAA) pattern provides a clear structure for organizing unit tests. In the Arrange phase, you set up the test conditions and inputs. In the Act phase, you execute the code under test. In the Assert phase, you verify the expected outcomes. This pattern makes tests easier to read, understand, and maintain.\n\nGood unit tests are isolated from external dependencies like databases, file systems, and network services. This isolation is achieved through techniques like dependency injection and the use of test doubles (mocks, stubs, fakes). Isolation ensures tests are fast, reliable, and focused on testing the specific unit of code.\n\nUnit testing provides several benefits including improved code quality, faster debugging, safer refactoring, and living documentation. Well-written unit tests serve as executable specifications that describe how code should behave, making it easier for new developers to understand the system.\n\nBy mastering unit testing principles, you'll be able to write tests that provide confidence in your code, catch bugs early, and make your software more maintainable.",
    "code": {
      "example": "// Service to be tested\npublic interface IEmailService\n{\n    bool SendEmail(string to, string subject, string body);\n}\n\npublic class UserService\n{\n    private readonly IEmailService _emailService;\n    \n    public UserService(IEmailService emailService)\n    {\n        _emailService = emailService;\n    }\n    \n    public bool RegisterUser(string email, string name)\n    {\n        // Validate inputs\n        if (string.IsNullOrEmpty(email) || string.IsNullOrEmpty(name))\n        {\n            return false;\n        }\n        \n        // Simulate user creation logic\n        var userCreated = CreateUserInDatabase(email, name);\n        \n        if (userCreated)\n        {\n            // Send welcome email\n            _emailService.SendEmail(email, \"Welcome!\", $\"Hello {name}, welcome to our service!\");\n        }\n        \n        return userCreated;\n    }\n    \n    private bool CreateUserInDatabase(string email, string name)\n    {\n        // Simulate database operation\n        return true; // Assume success for this example\n    }\n}\n\n// Unit test following FIRST principles and AAA pattern\nusing Xunit;\nusing Moq;\n\npublic class UserServiceTests\n{\n    [Fact]\n    public void RegisterUser_WithValidInputs_ReturnsTrue()\n    {\n        // Arrange\n        var mockEmailService = new Mock<IEmailService>();\n        mockEmailService.Setup(x => x.SendEmail(It.IsAny<string>(), It.IsAny<string>(), It.IsAny<string>()))\n                       .Returns(true);\n        \n        var userService = new UserService(mockEmailService.Object);\n        \n        // Act\n        var result = userService.RegisterUser(\"test@example.com\", \"John Doe\");\n        \n        // Assert\n        Assert.True(result);\n        mockEmailService.Verify(x => x.SendEmail(\"test@example.com\", \"Welcome!\", \"Hello John Doe, welcome to our service!\"), Times.Once);\n    }\n    \n    [Fact]\n    public void RegisterUser_WithNullEmail_ReturnsFalse()\n    {\n        // Arrange\n        var mockEmailService = new Mock<IEmailService>();\n        var userService = new UserService(mockEmailService.Object);\n        \n        // Act\n        var result = userService.RegisterUser(null, \"John Doe\");\n        \n        // Assert\n        Assert.False(result);\n        mockEmailService.Verify(x => x.SendEmail(It.IsAny<string>(), It.IsAny<string>(), It.IsAny<string>()), Times.Never);\n    }\n    \n    [Fact]\n    public void RegisterUser_WithEmptyName_ReturnsFalse()\n    {\n        // Arrange\n        var mockEmailService = new Mock<IEmailService>();\n        var userService = new UserService(mockEmailService.Object);\n        \n        // Act\n        var result = userService.RegisterUser(\"test@example.com\", \"\");\n        \n        // Assert\n        Assert.False(result);\n        mockEmailService.Verify(x => x.SendEmail(It.IsAny<string>(), It.IsAny<string>(), It.IsAny<string>()), Times.Never);\n    }\n}",
      "explanation": "This example demonstrates unit testing principles with a UserService class that depends on an IEmailService. The tests follow the FIRST principles: they're Fast (complete quickly), Independent (can run in any order), Repeatable (same results each time), Self-validating (automatically check results), and Thorough (cover multiple scenarios). Each test follows the Arrange-Act-Assert pattern and uses Moq to create a mock email service, isolating the unit under test from external dependencies.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Testing implementation details instead of behavior",
        "solution": "Focus on testing what the code does rather than how it does it, testing public interfaces rather than private methods",
        "severity": "high"
      },
      {
        "mistake": "Creating tests that are slow or unreliable",
        "solution": "Isolate tests from external dependencies, keep tests focused, and avoid unnecessary setup",
        "severity": "high"
      },
      {
        "mistake": "Not testing edge cases and error conditions",
        "solution": "Test boundary values, null inputs, and failure scenarios in addition to happy path cases",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Write Unit Tests for a Shopping Cart Service",
        "description": "Create comprehensive unit tests for a shopping cart service following best practices.",
        "checkpoints": [
          "Implement tests for adding items to the cart",
          "Test removing items from the cart",
          "Verify cart total calculation with multiple items",
          "Test edge cases like adding duplicate items",
          "Handle error conditions such as removing non-existent items"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-3"
    ],
    "estimatedMinutes": 60,
    "difficulty": "Intermediate",
    "tags": [
      "unit-testing",
      "first-principles",
      "aaa-pattern",
      "isolation"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 3,
    "moduleSlug": "testing-fundamentals",
    "title": "Test-Driven Development (TDD)",
    "order": 3,
    "objectives": [
      "Understand the Test-Driven Development (TDD) methodology",
      "Implement the Red-Green-Refactor cycle in practice",
      "Write tests before implementation code",
      "Refactor code confidently with comprehensive test coverage"
    ],
    "intro": "Test-Driven Development (TDD) is a software development approach where tests are written before the actual implementation code. This approach follows the Red-Green-Refactor cycle: first write a failing test (Red), then write the minimum code to make it pass (Green), and finally refactor the code while keeping all tests passing (Refactor).\n\nTDD provides several benefits including improved code design, better test coverage, reduced debugging time, and increased confidence when making changes. By writing tests first, developers are forced to think about the design and interface of their code before implementation, often leading to more modular and testable designs.\n\nThe Red-Green-Refactor cycle is the core of TDD practice. In the Red phase, you write a test that fails because the functionality doesn't exist yet. This ensures the test is actually testing something. In the Green phase, you write the minimum code necessary to make the test pass, focusing on functionality rather than perfection. In the Refactor phase, you improve the code's structure, performance, or readability while ensuring all tests continue to pass.\n\nTDD encourages developers to think in small increments, implementing functionality piece by piece rather than trying to build everything at once. This incremental approach leads to better design decisions and makes it easier to identify and fix problems early in the development process.\n\nCommon challenges with TDD include the initial learning curve, the discipline required to stick to the process, and knowing what to test. However, with practice, TDD becomes a natural part of the development workflow and leads to higher quality, more maintainable code.\n\nBy mastering TDD, you'll develop a more disciplined approach to software development, write better-designed code, and have greater confidence in the correctness of your implementations.",
    "code": {
      "example": "// Let's implement a StringCalculator class using TDD\n\n// Step 1: Write a failing test (Red)\n/*\npublic class StringCalculatorTests\n{\n    [Fact]\n    public void Add_EmptyString_ReturnsZero()\n    {\n        // Arrange\n        var calculator = new StringCalculator();\n        \n        // Act\n        var result = calculator.Add(\"\");\n        \n        // Assert\n        Assert.Equal(0, result);\n    }\n}\n*/\n\n// Step 2: Write minimum code to make test pass (Green)\n/*\npublic class StringCalculator\n{\n    public int Add(string numbers)\n    {\n        return 0; // Minimum implementation to pass the test\n    }\n}\n*/\n\n// Step 3: Add another test for a simple case\n/*\n[Fact]\npublic void Add_SingleNumber_ReturnsNumber()\n{\n    // Arrange\n    var calculator = new StringCalculator();\n    \n    // Act\n    var result = calculator.Add(\"1\");\n    \n    // Assert\n    Assert.Equal(1, result);\n}\n*/\n\n// Step 4: Update implementation to handle both cases\n/*\npublic class StringCalculator\n{\n    public int Add(string numbers)\n    {\n        if (string.IsNullOrEmpty(numbers))\n            return 0;\n            \n        return int.Parse(numbers);\n    }\n}\n*/\n\n// Step 5: Add test for two numbers\n/*\n[Fact]\npublic void Add_TwoNumbers_ReturnsSum()\n{\n    // Arrange\n    var calculator = new StringCalculator();\n    \n    // Act\n    var result = calculator.Add(\"1,2\");\n    \n    // Assert\n    Assert.Equal(3, result);\n}\n*/\n\n// Step 6: Update implementation\npublic class StringCalculator\n{\n    public int Add(string numbers)\n    {\n        if (string.IsNullOrEmpty(numbers))\n            return 0;\n            \n        var numberArray = numbers.Split(',');\n        var sum = 0;\n        \n        foreach (var number in numberArray)\n        {\n            sum += int.Parse(number);\n        }\n        \n        return sum;\n    }\n}\n\n// Continue this cycle for more complex requirements like handling newlines,\n// custom delimiters, negative numbers, etc.",
      "explanation": "This example demonstrates the TDD process by implementing a StringCalculator class. We start with the simplest test case (empty string returns zero), write minimal code to pass it, then add more complex test cases one by one. Each new test forces us to improve the implementation. This incremental approach ensures we only implement what's needed and leads to well-tested, well-designed code.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Writing tests that are too complex or try to test too much at once",
        "solution": "Start with simple test cases and gradually increase complexity, following the 'simplest thing that could possibly work' principle",
        "severity": "high"
      },
      {
        "mistake": "Skipping the refactoring step or refactoring without tests",
        "solution": "Always refactor with confidence by keeping all tests passing, and never refactor without comprehensive test coverage",
        "severity": "high"
      },
      {
        "mistake": "Writing implementation code before tests",
        "solution": "Stick to the discipline of writing tests first, even when it feels slower initially",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement a Password Validator Using TDD",
        "description": "Create a password validation service using strict TDD methodology.",
        "checkpoints": [
          "Start with the simplest test case (empty password) and make it pass",
          "Gradually add more complex requirements one by one",
          "Follow the Red-Green-Refactor cycle for each new requirement",
          "Refactor the implementation as needed while keeping all tests green",
          "Handle edge cases like null inputs and very long passwords"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-4"
    ],
    "estimatedMinutes": 75,
    "difficulty": "Intermediate",
    "tags": [
      "tdd",
      "red-green-refactor",
      "test-first",
      "design"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 4,
    "moduleSlug": "testing-fundamentals",
    "title": "Mocking and Test Doubles",
    "order": 4,
    "objectives": [
      "Understand different types of test doubles: mocks, stubs, fakes, and spies",
      "Implement mocking frameworks to isolate units of code",
      "Create effective test doubles that accurately simulate dependencies",
      "Verify interactions between objects using mocks"
    ],
    "intro": "Mocking is a technique used in unit testing to isolate the unit of code under test from its dependencies. Test doubles are objects that replace real dependencies in tests, allowing you to control their behavior and verify interactions. Understanding the different types of test doubles and when to use each is crucial for effective unit testing.\n\nThere are several types of test doubles: Stubs provide canned answers to calls made during the test, usually not responding at all to anything outside what's programmed for the test. Mocks are stubs with added behavior verification - they know what methods should be called and with what arguments, and can verify this during the test. Fakes are working implementations of dependencies that aren't suitable for production (like an in-memory database). Spies record information about method calls for later verification.\n\nMocking frameworks like Moq, NSubstitute, and FakeItEasy provide powerful features for creating test doubles with minimal code. These frameworks allow you to set up return values, throw exceptions, verify method calls, and configure complex behavior scenarios. They also provide clear error messages when tests fail, making debugging easier.\n\nEffective mocking requires understanding what to mock and what not to mock. Generally, you should mock external dependencies like databases, web services, and file systems, but not simple data structures or utility classes. It's also important to avoid over-mocking, which can lead to brittle tests that are tightly coupled to implementation details.\n\nBest practices for mocking include mocking only what you own (preferably), keeping mocks simple, verifying behavior rather than implementation, and isolating tests to ensure they're independent and repeatable. Good mocks make tests faster, more reliable, and easier to maintain.\n\nBy mastering mocking techniques, you'll be able to write unit tests that are fast, reliable, and focused on testing the specific behavior of your code rather than its dependencies.",
    "code": {
      "example": "// Different types of test doubles example\n\n// Interface for real dependency\npublic interface IUserRepository\n{\n    User GetUserById(int id);\n    void SaveUser(User user);\n    List<User> GetAllUsers();\n}\n\n// Real implementation (what we'd use in production)\npublic class DatabaseUserRepository : IUserRepository\n{\n    public User GetUserById(int id)\n    {\n        // Connect to database and retrieve user\n        // This is slow and requires a database connection\n        throw new NotImplementedException();\n    }\n    \n    public void SaveUser(User user)\n    {\n        // Save user to database\n        throw new NotImplementedException();\n    }\n    \n    public List<User> GetAllUsers()\n    {\n        // Retrieve all users from database\n        throw new NotImplementedException();\n    }\n}\n\n// Fake implementation (test double)\npublic class InMemoryUserRepository : IUserRepository\n{\n    private readonly Dictionary<int, User> _users = new Dictionary<int, User>();\n    \n    public User GetUserById(int id)\n    {\n        return _users.ContainsKey(id) ? _users[id] : null;\n    }\n    \n    public void SaveUser(User user)\n    {\n        _users[user.Id] = user;\n    }\n    \n    public List<User> GetAllUsers()\n    {\n        return _users.Values.ToList();\n    }\n}\n\n// Service under test\npublic class UserService\n{\n    private readonly IUserRepository _userRepository;\n    \n    public UserService(IUserRepository userRepository)\n    {\n        _userRepository = userRepository;\n    }\n    \n    public User GetUserProfile(int userId)\n    {\n        var user = _userRepository.GetUserById(userId);\n        if (user == null)\n        {\n            throw new UserNotFoundException($\"User with ID {userId} not found\");\n        }\n        return user;\n    }\n    \n    public void RegisterUser(User user)\n    {\n        // Check if user already exists\n        var existingUser = _userRepository.GetUserById(user.Id);\n        if (existingUser != null)\n        {\n            throw new DuplicateUserException($\"User with ID {user.Id} already exists\");\n        }\n        \n        _userRepository.SaveUser(user);\n    }\n}\n\n// Unit tests using different test doubles\nusing Xunit;\nusing Moq;\n\npublic class UserServiceTests\n{\n    [Fact]\n    public void GetUserProfile_ExistingUser_ReturnsUser()\n    {\n        // Using a mock (test double)\n        var mockRepository = new Mock<IUserRepository>();\n        var expectedUser = new User { Id = 1, Name = \"John Doe\" };\n        mockRepository.Setup(x => x.GetUserById(1)).Returns(expectedUser);\n        \n        var userService = new UserService(mockRepository.Object);\n        \n        var result = userService.GetUserProfile(1);\n        \n        Assert.Equal(expectedUser, result);\n        mockRepository.Verify(x => x.GetUserById(1), Times.Once);\n    }\n    \n    [Fact]\n    public void GetUserProfile_NonExistingUser_ThrowsException()\n    {\n        // Using a stub (test double)\n        var mockRepository = new Mock<IUserRepository>();\n        mockRepository.Setup(x => x.GetUserById(It.IsAny<int>())).Returns((User)null);\n        \n        var userService = new UserService(mockRepository.Object);\n        \n        Assert.Throws<UserNotFoundException>(() => userService.GetUserProfile(999));\n    }\n    \n    [Fact]\n    public void RegisterUser_NewUser_SavesUser()\n    {\n        // Using a fake (test double)\n        var fakeRepository = new InMemoryUserRepository();\n        var userService = new UserService(fakeRepository);\n        var newUser = new User { Id = 1, Name = \"John Doe\" };\n        \n        userService.RegisterUser(newUser);\n        \n        var savedUser = fakeRepository.GetUserById(1);\n        Assert.NotNull(savedUser);\n        Assert.Equal(\"John Doe\", savedUser.Name);\n    }\n}",
      "explanation": "This example demonstrates different types of test doubles. The DatabaseUserRepository is a real implementation that would connect to a database. The InMemoryUserRepository is a fake - a working implementation suitable for testing. The tests show how to use mocks (with Moq) for verification and stubs for providing canned responses. Each type of test double serves a different purpose and is appropriate for different testing scenarios.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Over-mocking and testing implementation details",
        "solution": "Mock only external dependencies and focus on testing behavior rather than implementation details",
        "severity": "high"
      },
      {
        "mistake": "Creating complex mocks that are hard to maintain",
        "solution": "Keep mocks simple and focused, and prefer fakes for complex scenarios",
        "severity": "medium"
      },
      {
        "mistake": "Not verifying mock expectations",
        "solution": "Always verify that expected method calls were made when using mocks for behavior verification",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Create Test Doubles for an Email Notification Service",
        "description": "Implement different types of test doubles for an email service dependency.",
        "checkpoints": [
          "Create a stub that returns predefined responses for email sending",
          "Implement a mock that verifies email sending interactions",
          "Build a fake email service that stores sent emails in memory",
          "Write tests using each type of test double",
          "Compare the advantages and disadvantages of each approach"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-5"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Intermediate",
    "tags": [
      "mocking",
      "test-doubles",
      "stubs",
      "mocks",
      "fakes"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 5,
    "moduleSlug": "testing-fundamentals",
    "title": "Integration Testing",
    "order": 5,
    "objectives": [
      "Understand the purpose and scope of integration testing",
      "Implement integration tests that verify component interactions",
      "Configure test environments for integration testing",
      "Handle test data and external dependencies in integration tests"
    ],
    "intro": "Integration testing verifies that different modules or services used by your application work well together. Unlike unit tests that isolate individual components, integration tests check the interfaces between components and the interactions with external systems like databases, web services, and file systems.\n\nIntegration tests occupy a middle ground in the testing pyramid between fast, isolated unit tests and slow, broad end-to-end tests. They're more comprehensive than unit tests but faster and more focused than end-to-end tests. Integration tests are particularly valuable for catching issues that unit tests might miss, such as incorrect database queries, misconfigured services, or broken API contracts.\n\nEffective integration testing requires careful test environment setup. This often involves using test databases, mock services, or containerized environments that closely resemble production. Test data management is crucial - you need consistent, repeatable data sets that allow tests to run reliably without interfering with each other.\n\nConfiguration management is another important aspect of integration testing. Tests should be able to run in different environments (development, CI, staging) without requiring manual configuration changes. This is typically achieved through environment variables, configuration files, or dependency injection.\n\nBest practices for integration testing include keeping tests focused on specific integration points, using appropriate test data that covers edge cases, cleaning up test data after tests run, and running integration tests in a consistent environment. It's also important to strike the right balance between test coverage and test execution time.\n\nCommon challenges in integration testing include test flakiness due to external dependencies, slow test execution, and difficulty in setting up and maintaining test environments. These challenges can be addressed through proper test design, infrastructure as code, and continuous integration practices.\n\nBy mastering integration testing, you'll be able to catch integration issues early, verify that your application works correctly with external systems, and build confidence in your application's overall functionality.",
    "code": {
      "example": "// Example of integration testing with a database\n\n// Entity class\npublic class Product\n{\n    public int Id { get; set; }\n    public string Name { get; set; }\n    public decimal Price { get; set; }\n    public DateTime CreatedAt { get; set; }\n}\n\n// Repository interface\npublic interface IProductRepository\n{\n    Task<Product> GetProductByIdAsync(int id);\n    Task<List<Product>> GetAllProductsAsync();\n    Task<Product> CreateProductAsync(Product product);\n    Task<bool> UpdateProductAsync(Product product);\n    Task<bool> DeleteProductAsync(int id);\n}\n\n// Implementation using Entity Framework\npublic class ProductRepository : IProductRepository\n{\n    private readonly ProductContext _context;\n    \n    public ProductRepository(ProductContext context)\n    {\n        _context = context;\n    }\n    \n    public async Task<Product> GetProductByIdAsync(int id)\n    {\n        return await _context.Products.FindAsync(id);\n    }\n    \n    public async Task<List<Product>> GetAllProductsAsync()\n    {\n        return await _context.Products.ToListAsync();\n    }\n    \n    public async Task<Product> CreateProductAsync(Product product)\n    {\n        _context.Products.Add(product);\n        await _context.SaveChangesAsync();\n        return product;\n    }\n    \n    public async Task<bool> UpdateProductAsync(Product product)\n    {\n        _context.Products.Update(product);\n        var result = await _context.SaveChangesAsync();\n        return result > 0;\n    }\n    \n    public async Task<bool> DeleteProductAsync(int id)\n    {\n        var product = await _context.Products.FindAsync(id);\n        if (product == null) return false;\n        \n        _context.Products.Remove(product);\n        var result = await _context.SaveChangesAsync();\n        return result > 0;\n    }\n}\n\n// Integration test using xUnit and in-memory database\nusing Xunit;\nusing Microsoft.EntityFrameworkCore;\nusing System.Threading.Tasks;\n\npublic class ProductRepositoryTests : IDisposable\n{\n    private readonly ProductContext _context;\n    private readonly ProductRepository _repository;\n    \n    public ProductRepositoryTests()\n    {\n        // Set up in-memory database for testing\n        var options = new DbContextOptionsBuilder<ProductContext>()\n            .UseInMemoryDatabase(databaseName: Guid.NewGuid().ToString())\n            .Options;\n            \n        _context = new ProductContext(options);\n        _repository = new ProductRepository(_context);\n        \n        // Seed test data\n        _context.Products.AddRange(\n            new Product { Id = 1, Name = \"Laptop\", Price = 999.99m, CreatedAt = DateTime.UtcNow },\n            new Product { Id = 2, Name = \"Mouse\", Price = 29.99m, CreatedAt = DateTime.UtcNow }\n        );\n        _context.SaveChanges();\n    }\n    \n    [Fact]\n    public async Task GetProductByIdAsync_ExistingProduct_ReturnsProduct()\n    {\n        // Act\n        var result = await _repository.GetProductByIdAsync(1);\n        \n        // Assert\n        Assert.NotNull(result);\n        Assert.Equal(\"Laptop\", result.Name);\n        Assert.Equal(999.99m, result.Price);\n    }\n    \n    [Fact]\n    public async Task CreateProductAsync_ValidProduct_AddsToDatabase()\n    {\n        // Arrange\n        var newProduct = new Product \n        { \n            Name = \"Keyboard\", \n            Price = 79.99m, \n            CreatedAt = DateTime.UtcNow \n        };\n        \n        // Act\n        var result = await _repository.CreateProductAsync(newProduct);\n        \n        // Assert\n        Assert.NotNull(result);\n        Assert.True(result.Id > 0);\n        \n        // Verify it was actually saved\n        var savedProduct = await _context.Products.FindAsync(result.Id);\n        Assert.NotNull(savedProduct);\n        Assert.Equal(\"Keyboard\", savedProduct.Name);\n    }\n    \n    [Fact]\n    public async Task UpdateProductAsync_ExistingProduct_UpdatesDatabase()\n    {\n        // Arrange\n        var product = await _context.Products.FindAsync(1);\n        product.Price = 899.99m;\n        \n        // Act\n        var result = await _repository.UpdateProductAsync(product);\n        \n        // Assert\n        Assert.True(result);\n        \n        // Verify the update was persisted\n        var updatedProduct = await _context.Products.FindAsync(1);\n        Assert.Equal(899.99m, updatedProduct.Price);\n    }\n    \n    public void Dispose()\n    {\n        _context?.Dispose();\n    }\n}",
      "explanation": "This example demonstrates integration testing with a database using Entity Framework. The test uses an in-memory database to avoid requiring a real database connection while still testing the actual EF integration. The test class implements IDisposable to clean up resources after tests run. Each test verifies that the repository methods work correctly with the database, covering CRUD operations. This approach provides confidence that the data access layer works correctly without the complexity of managing a separate test database.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Making integration tests too slow or unreliable",
        "solution": "Use in-memory databases or mock services where appropriate, and ensure tests are independent and repeatable",
        "severity": "high"
      },
      {
        "mistake": "Not managing test data properly",
        "solution": "Use transactions that can be rolled back, or clean up test data after each test to ensure tests don't interfere with each other",
        "severity": "high"
      },
      {
        "mistake": "Testing too much in a single integration test",
        "solution": "Keep integration tests focused on specific integration points rather than trying to test entire workflows",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Create Integration Tests for a REST API Client",
        "description": "Implement integration tests for a service that consumes a REST API.",
        "checkpoints": [
          "Set up a test environment with a mock HTTP server",
          "Test successful API calls and response handling",
          "Verify error handling for different HTTP status codes",
          "Test timeout and network failure scenarios",
          "Ensure tests are isolated and don't depend on external services"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-6"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Intermediate",
    "tags": [
      "integration-testing",
      "databases",
      "external-dependencies",
      "test-environments"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 6,
    "moduleSlug": "testing-fundamentals",
    "title": "Testing Frameworks and Tools",
    "order": 6,
    "objectives": [
      "Compare popular testing frameworks for different programming languages",
      "Configure and use xUnit, NUnit, and MSTest for .NET testing",
      "Implement test runners and continuous integration with testing",
      "Utilize advanced testing features like parameterized tests and fixtures"
    ],
    "intro": "Testing frameworks provide the foundation for writing and executing tests in modern software development. Different frameworks offer various features, syntax styles, and extensibility options that can significantly impact your testing experience and productivity.\n\nIn the .NET ecosystem, xUnit, NUnit, and MSTest are the three primary testing frameworks. xUnit is the most modern and is designed specifically for .NET, offering features like parameterized tests, test fixtures, and extensibility. NUnit is a mature framework with a rich feature set and extensive documentation. MSTest is Microsoft's official testing framework, well-integrated with Visual Studio and Azure DevOps.\n\nEach framework has its strengths: xUnit emphasizes test isolation and provides clean, modern syntax; NUnit offers extensive assertion capabilities and flexible test organization; MSTest provides excellent IDE integration and is well-suited for enterprise environments. Choosing the right framework depends on your team's preferences, project requirements, and existing tooling.\n\nModern testing frameworks provide advanced features that make testing more efficient and expressive. Parameterized tests allow you to run the same test logic with different input data, reducing code duplication. Test fixtures enable setup and teardown logic that runs before and after tests. Assertion libraries provide fluent APIs for expressing test expectations clearly.\n\nTest runners are tools that discover, execute, and report on tests. They can run tests in parallel, provide detailed reporting, and integrate with continuous integration systems. Popular test runners include the built-in runners for each framework, ReSharper, and command-line tools like `dotnet test`.\n\nContinuous integration (CI) systems play a crucial role in automated testing. They automatically run tests when code changes are committed, providing rapid feedback to developers. Configuring CI to run tests effectively requires understanding how to set up test environments, manage test data, and interpret test results.\n\nBy mastering testing frameworks and tools, you'll be able to write more effective tests, automate your testing process, and integrate testing seamlessly into your development workflow.",
    "code": {
      "example": "// Example showing different .NET testing frameworks\n\n// xUnit example\nusing Xunit;\nusing System.Collections.Generic;\n\npublic class CalculatorTests\n{\n    private readonly Calculator _calculator;\n    \n    public CalculatorTests()\n    {\n        _calculator = new Calculator();\n    }\n    \n    // Simple test\n    [Fact]\n    public void Add_WhenGivenTwoNumbers_ReturnsTheirSum()\n    {\n        var result = _calculator.Add(2, 3);\n        Assert.Equal(5, result);\n    }\n    \n    // Parameterized test\n    [Theory]\n    [InlineData(1, 2, 3)]\n    [InlineData(-1, 1, 0)]\n    [InlineData(0, 0, 0)]\n    public void Add_WithVariousInputs_ReturnsCorrectResult(int a, int b, int expected)\n    {\n        var result = _calculator.Add(a, b);\n        Assert.Equal(expected, result);\n    }\n    \n    // Async test\n    [Fact]\n    public async Task DivideAsync_WhenDivisorIsZero_ThrowsException()\n    {\n        await Assert.ThrowsAsync<DivideByZeroException>(() => \n            _calculator.DivideAsync(10, 0));\n    }\n}\n\n// NUnit example\nusing NUnit.Framework;\nusing System.Collections.Generic;\n\n[TestFixture]\npublic class CalculatorNUnitTests\n{\n    private Calculator _calculator;\n    \n    [SetUp]\n    public void Setup()\n    {\n        _calculator = new Calculator();\n    }\n    \n    [Test]\n    public void Add_WhenGivenTwoNumbers_ReturnsTheirSum()\n    {\n        var result = _calculator.Add(2, 3);\n        Assert.That(result, Is.EqualTo(5));\n    }\n    \n    [TestCase(1, 2, 3)]\n    [TestCase(-1, 1, 0)]\n    [TestCase(0, 0, 0)]\n    public void Add_WithVariousInputs_ReturnsCorrectResult(int a, int b, int expected)\n    {\n        var result = _calculator.Add(a, b);\n        Assert.That(result, Is.EqualTo(expected));\n    }\n    \n    [Test]\n    public void Divide_WhenDivisorIsZero_ThrowsException()\n    {\n        var ex = Assert.Throws<DivideByZeroException>(() => \n            _calculator.Divide(10, 0));\n        Assert.That(ex.Message, Does.Contain(\"Cannot divide by zero\"));\n    }\n}\n\n// MSTest example\nusing Microsoft.VisualStudio.TestTools.UnitTesting;\nusing System.Collections.Generic;\n\n[TestClass]\npublic class CalculatorMSTestTests\n{\n    private Calculator _calculator;\n    \n    [TestInitialize]\n    public void Setup()\n    {\n        _calculator = new Calculator();\n    }\n    \n    [TestMethod]\n    public void Add_WhenGivenTwoNumbers_ReturnsTheirSum()\n    {\n        var result = _calculator.Add(2, 3);\n        Assert.AreEqual(5, result);\n    }\n    \n    [DataTestMethod]\n    [DataRow(1, 2, 3)]\n    [DataRow(-1, 1, 0)]\n    [DataRow(0, 0, 0)]\n    public void Add_WithVariousInputs_ReturnsCorrectResult(int a, int b, int expected)\n    {\n        var result = _calculator.Add(a, b);\n        Assert.AreEqual(expected, result);\n    }\n    \n    [TestMethod]\n    [ExpectedException(typeof(DivideByZeroException))]\n    public void Divide_WhenDivisorIsZero_ThrowsException()\n    {\n        _calculator.Divide(10, 0);\n    }\n}",
      "explanation": "This example demonstrates the syntax differences between the three major .NET testing frameworks. xUnit uses [Fact] and [Theory] attributes with Assert methods. NUnit uses [TestFixture], [Test], and [TestCase] with a fluent assertion syntax. MSTest uses [TestClass], [TestMethod], and [DataTestMethod] with Assert methods. Each framework has its own approach to test organization, parameterized tests, and assertion syntax, but they all serve the same fundamental purpose of enabling automated testing.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Choosing a framework based only on popularity rather than suitability for your project",
        "solution": "Evaluate frameworks based on your team's needs, project requirements, and existing tooling rather than just popularity",
        "severity": "medium"
      },
      {
        "mistake": "Not leveraging advanced framework features like parameterized tests",
        "solution": "Use parameterized tests, test fixtures, and other advanced features to reduce code duplication and improve test coverage",
        "severity": "medium"
      },
      {
        "mistake": "Ignoring test runner configuration and performance",
        "solution": "Configure test runners for parallel execution and proper reporting, and monitor test execution performance",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Compare Testing Frameworks for a New Project",
        "description": "Evaluate different testing frameworks and set up a testing environment.",
        "checkpoints": [
          "Create simple tests using xUnit, NUnit, and MSTest",
          "Compare syntax, features, and ease of use",
          "Configure test runners and CI integration",
          "Implement parameterized tests and test fixtures",
          "Document recommendations for framework selection"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-7"
    ],
    "estimatedMinutes": 75,
    "difficulty": "Intermediate",
    "tags": [
      "testing-frameworks",
      "xunit",
      "nunit",
      "mstest",
      "test-runners"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 7,
    "moduleSlug": "testing-fundamentals",
    "title": "Code Coverage and Quality Metrics",
    "order": 7,
    "objectives": [
      "Understand code coverage metrics and their significance",
      "Measure and analyze code coverage in .NET applications",
      "Interpret coverage reports to identify untested code",
      "Establish quality gates based on coverage metrics"
    ],
    "intro": "Code coverage is a metric that measures the degree to which the source code of a program is executed when a test suite runs. It's expressed as a percentage and indicates how much of your code is being tested. While high coverage doesn't guarantee good tests, low coverage is often a red flag indicating insufficient testing.\n\nThere are several types of code coverage metrics, each measuring different aspects of code execution. Statement coverage measures the percentage of executable statements that have been executed. Branch coverage measures the percentage of decision points (if statements, loops) that have been taken. Function coverage measures the percentage of functions that have been called. Line coverage is similar to statement coverage but measures lines of code.\n\nIn .NET, tools like Coverlet, Visual Studio Code Coverage, and AltCover can measure code coverage during test execution. These tools instrument the code to track which parts are executed by tests, then generate detailed reports showing coverage statistics and highlighting uncovered code.\n\nInterpreting coverage reports requires understanding that 100% coverage doesn't mean bug-free code. Tests might execute all code paths but still have incorrect assertions or miss important edge cases. Conversely, lower coverage might be acceptable for certain types of code like simple data transfer objects or auto-generated code.\n\nEffective use of code coverage involves setting appropriate targets based on project requirements and risk tolerance. Many teams aim for 80% coverage as a reasonable balance between thorough testing and practicality. Critical business logic might require higher coverage, while utility code might have lower requirements.\n\nQuality gates can be established in continuous integration pipelines to enforce coverage requirements. If coverage drops below a threshold, the build can fail, preventing poorly tested code from being merged. However, it's important to use coverage as a guide rather than a strict gate to avoid gaming the metric.\n\nBy mastering code coverage and quality metrics, you'll be able to measure the effectiveness of your test suite, identify areas that need more testing, and make data-driven decisions about code quality.",
    "code": {
      "example": "// Example code to measure coverage\n\npublic class BankAccount\n{\n    public decimal Balance { get; private set; }\n    public string AccountNumber { get; }\n    \n    public BankAccount(string accountNumber, decimal initialBalance = 0)\n    {\n        AccountNumber = accountNumber;\n        Balance = initialBalance;\n    }\n    \n    public void Deposit(decimal amount)\n    {\n        if (amount <= 0)\n        {\n            throw new ArgumentException(\"Deposit amount must be positive\");\n        }\n        \n        Balance += amount;\n    }\n    \n    public void Withdraw(decimal amount)\n    {\n        if (amount <= 0)\n        {\n            throw new ArgumentException(\"Withdrawal amount must be positive\");\n        }\n        \n        if (amount > Balance)\n        {\n            throw new InvalidOperationException(\"Insufficient funds\");\n        }\n        \n        Balance -= amount;\n    }\n    \n    public bool TransferTo(BankAccount targetAccount, decimal amount)\n    {\n        if (targetAccount == null)\n        {\n            throw new ArgumentNullException(nameof(targetAccount));\n        }\n        \n        // This is a business rule - can't transfer to same account\n        if (targetAccount.AccountNumber == AccountNumber)\n        {\n            return false;\n        }\n        \n        Withdraw(amount);\n        targetAccount.Deposit(amount);\n        return true;\n    }\n}\n\n// Tests that provide good coverage\nusing Xunit;\n\npublic class BankAccountTests\n{\n    [Fact]\n    public void Deposit_WithPositiveAmount_IncreasesBalance()\n    {\n        var account = new BankAccount(\"12345\", 100);\n        \n        account.Deposit(50);\n        \n        Assert.Equal(150, account.Balance);\n    }\n    \n    [Fact]\n    public void Deposit_WithZeroAmount_ThrowsException()\n    {\n        var account = new BankAccount(\"12345\");\n        \n        Assert.Throws<ArgumentException>(() => account.Deposit(0));\n    }\n    \n    [Fact]\n    public void Deposit_WithNegativeAmount_ThrowsException()\n    {\n        var account = new BankAccount(\"12345\");\n        \n        Assert.Throws<ArgumentException>(() => account.Deposit(-10));\n    }\n    \n    [Fact]\n    public void Withdraw_WithSufficientFunds_DecreasesBalance()\n    {\n        var account = new BankAccount(\"12345\", 100);\n        \n        account.Withdraw(30);\n        \n        Assert.Equal(70, account.Balance);\n    }\n    \n    [Fact]\n    public void Withdraw_WithInsufficientFunds_ThrowsException()\n    {\n        var account = new BankAccount(\"12345\", 50);\n        \n        Assert.Throws<InvalidOperationException>(() => account.Withdraw(100));\n    }\n    \n    [Fact]\n    public void TransferTo_ValidAccount_TransfersFunds()\n    {\n        var sourceAccount = new BankAccount(\"12345\", 100);\n        var targetAccount = new BankAccount(\"67890\", 50);\n        \n        var result = sourceAccount.TransferTo(targetAccount, 30);\n        \n        Assert.True(result);\n        Assert.Equal(70, sourceAccount.Balance);\n        Assert.Equal(80, targetAccount.Balance);\n    }\n    \n    [Fact]\n    public void TransferTo_SameAccount_ReturnsFalse()\n    {\n        var account = new BankAccount(\"12345\", 100);\n        \n        var result = account.TransferTo(account, 30);\n        \n        Assert.False(result);\n        Assert.Equal(100, account.Balance); // Balance should be unchanged\n    }\n    \n    [Fact]\n    public void TransferTo_NullAccount_ThrowsException()\n    {\n        var account = new BankAccount(\"12345\", 100);\n        \n        Assert.Throws<ArgumentNullException>(() => account.TransferTo(null, 30));\n    }\n}",
      "explanation": "This example shows a BankAccount class with several methods that have different code paths. The tests provide comprehensive coverage by testing normal cases, edge cases, and error conditions. Each method has tests for its main functionality as well as tests for its validation logic. This approach ensures that all branches of the code are executed during testing, leading to high code coverage. Tools like Coverlet can measure the actual coverage percentage and highlight any lines that aren't executed by tests.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Focusing only on coverage percentage rather than test quality",
        "solution": "Use coverage as a guide to identify untested code, but prioritize writing meaningful tests over achieving arbitrary coverage targets",
        "severity": "high"
      },
      {
        "mistake": "Not considering the context when setting coverage targets",
        "solution": "Set different coverage requirements for different parts of the codebase based on risk and complexity",
        "severity": "medium"
      },
      {
        "mistake": "Ignoring uncovered code that should be tested",
        "solution": "Regularly review coverage reports to identify and address gaps in test coverage",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Measure and Improve Code Coverage for a Service Class",
        "description": "Analyze code coverage for an existing service and improve test coverage.",
        "checkpoints": [
          "Run code coverage analysis on an existing service class",
          "Identify uncovered code paths and edge cases",
          "Write additional tests to improve coverage",
          "Set up coverage reporting in a CI pipeline",
          "Document coverage requirements for different types of code"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-8"
    ],
    "estimatedMinutes": 75,
    "difficulty": "Intermediate",
    "tags": [
      "code-coverage",
      "metrics",
      "coverlet",
      "quality-gates",
      "analysis"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 8,
    "moduleSlug": "testing-fundamentals",
    "title": "Behavior-Driven Development (BDD)",
    "order": 8,
    "objectives": [
      "Understand the principles and benefits of Behavior-Driven Development",
      "Write executable specifications using Gherkin syntax",
      "Implement BDD frameworks like SpecFlow or BDDfy",
      "Collaborate effectively with stakeholders using BDD practices"
    ],
    "intro": "Behavior-Driven Development (BDD) is an agile software development methodology that encourages collaboration between developers, QA, and non-technical stakeholders in a software project. BDD extends Test-Driven Development by writing tests in a natural language that non-programmers can read and understand.\n\nThe core principle of BDD is to focus on the behavior of the system from the user's perspective rather than implementation details. This approach helps ensure that everyone involved in the project has a shared understanding of what the software should do. BDD bridges the communication gap between technical and non-technical team members.\n\nGherkin is the language used to write BDD specifications. It uses a structured format with keywords like Feature, Scenario, Given, When, and Then to describe system behavior in a readable way. Feature files contain high-level descriptions of system capabilities, while scenarios describe specific examples of how the system should behave.\n\nBDD frameworks like SpecFlow (for .NET), Cucumber (for Java/Ruby), and Behave (for Python) allow these natural language specifications to be executed as automated tests. These frameworks parse Gherkin feature files and map the steps to implementation code, creating executable specifications that serve as both documentation and tests.\n\nThe BDD process typically involves three stages: Discovery, where stakeholders collaborate to define system behavior; Formulation, where scenarios are written in Gherkin; and Automation, where step definitions are implemented to execute the scenarios. This process ensures that development is driven by business requirements rather than technical implementation details.\n\nEffective BDD requires a cultural shift toward collaboration and shared understanding. It works best when business stakeholders, developers, and testers work together throughout the development process. The living documentation created through BDD becomes a valuable asset that evolves with the system.\n\nBy mastering BDD, you'll improve communication within your team, create executable specifications that serve as documentation, and ensure that development focuses on delivering business value.",
    "code": {
      "example": "# Feature file (Calculator.feature)\nFeature: Calculator\n  In order to perform basic arithmetic operations\n  As a user\n  I want to use a calculator to add and subtract numbers\n\n  Scenario: Add two positive numbers\n    Given I have a calculator\n    And I have entered 50 into the calculator\n    And I have entered 70 into the calculator\n    When I press add\n    Then the result should be 120 on the screen\n\n  Scenario: Subtract two numbers\n    Given I have a calculator\n    And I have entered 100 into the calculator\n    And I have entered 30 into the calculator\n    When I press subtract\n    Then the result should be 70 on the screen\n\n  Scenario Outline: Add numbers from examples\n    Given I have a calculator\n    And I have entered <first> into the calculator\n    And I have entered <second> into the calculator\n    When I press add\n    Then the result should be <result> on the screen\n\n    Examples:\n      | first | second | result |\n      | 20    | 30     | 50     |\n      | 2     | 5      | 7      |\n      | 0     | 40     | 40     |\n\n// Step definition file (CalculatorSteps.cs)\nusing TechTalk.SpecFlow;\nusing Xunit;\n\n[Binding]\npublic class CalculatorSteps\n{\n    private Calculator _calculator;\n    private int _result;\n    \n    [Given(\"I have a calculator\")]\n    public void GivenIHaveACalculator()\n    {\n        _calculator = new Calculator();\n    }\n    \n    [Given(\"I have entered (.*) into the calculator\")]\n    public void GivenIHaveEnteredIntoTheCalculator(int number)\n    {\n        _calculator.EnterNumber(number);\n    }\n    \n    [When(\"I press add\")]\n    public void WhenIPressAdd()\n    {\n        _result = _calculator.Add();\n    }\n    \n    [When(\"I press subtract\")]\n    public void WhenIPressSubtract()\n    {\n        _result = _calculator.Subtract();\n    }\n    \n    [Then(\"the result should be (.*) on the screen\")]\n    public void ThenTheResultShouldBeOnTheScreen(int expectedResult)\n    {\n        Assert.Equal(expectedResult, _result);\n    }\n}\n\n// Implementation class (Calculator.cs)\npublic class Calculator\n{\n    private readonly List<int> _numbers = new List<int>();\n    \n    public void EnterNumber(int number)\n    {\n        _numbers.Add(number);\n    }\n    \n    public int Add()\n    {\n        return _numbers.Sum();\n    }\n    \n    public int Subtract()\n    {\n        if (_numbers.Count < 2) return 0;\n        return _numbers[0] - _numbers[1];\n    }\n}\n\n      \"explanation\": \"This example shows a BDD implementation using SpecFlow. The feature file describes the calculator functionality in natural language that business stakeholders can understand. The step definitions map each Gherkin step to actual code implementation. The calculator class provides the actual functionality. This approach creates living documentation that serves as both requirements and automated tests.\",\n      \"language\": \"csharp\"\n    },\n    \"pitfalls\": [\n      {\n        \"mistake\": \"Writing scenarios that are too technical or too vague\",\n        \"solution\": \"Work with business stakeholders to write scenarios in clear, business-focused language using concrete examples\",\n        \"severity\": \"high\"\n      },\n      {\n        \"mistake\": \"Creating too many scenario outlines with excessive examples\",\n        \"solution\": \"Focus on the most important examples that illustrate different behaviors and edge cases\",\n        \"severity\": \"medium\"\n      },\n      {\n        \"mistake\": \"Not maintaining scenarios as the system evolves\",\n        \"solution\": \"Regularly review and update scenarios to ensure they reflect current system behavior\",\n        \"severity\": \"medium\"\n      }\n    ],\n    \"exercises\": [\n      {\n        \"title\": \"Implement a Shopping Cart Feature with BDD\",\n        \"description\": \"Create BDD specifications and implementation for a shopping cart feature.\",\n        \"checkpoints\": [\n          \"Write feature files describing shopping cart functionality in business language\",\n          \"Create scenarios for adding, removing, and updating items\",\n          \"Implement step definitions that map to actual code\",\n          \"Handle edge cases like out-of-stock items or quantity limits\",\n          \"Run scenarios as automated tests to validate implementation\"\n        ]\n      }\n    ],\n    \"next\": [\n      \"testing-fundamentals-lesson-9\"\n    ],\n    \"estimatedMinutes\": 90,\n    \"difficulty\": \"Intermediate\",\n    \"tags\": [\n      \"bdd\",\n      \"specflow\",\n      \"gherkin\",\n      \"collaboration\",\n      \"specifications\"\n    ],\n    \"lastUpdated\": \"2025-10-09T10:00:00.000Z\",\n    \"version\": \"1.0.0\"\n  },\n  {\n    \"id\": \"testing-fundamentals-lesson-9\",\n    \"moduleSlug\": \"testing-fundamentals\",\n    \"title\": \"Testing Best Practices\",\n    \"order\": 9,\n    \"objectives\": [\n      \"Apply industry-standard testing best practices\",\n      \"Organize and structure test code for maintainability\",\n      \"Implement effective test data management strategies\",\n      \"Follow naming conventions and coding standards for tests\"\n    ],\n    \"intro\": \"Testing best practices are guidelines and principles that help teams write effective, maintainable, and reliable tests. These practices have been developed through years of experience in the software industry and represent proven approaches to testing.\n\nOne of the most important best practices is the use of the AAA (Arrange-Act-Assert) pattern for structuring tests. This pattern makes tests easier to read and understand by clearly separating the setup, execution, and verification phases. Consistent structure across tests makes it easier for team members to work with the test suite.\n\nEffective test naming is crucial for maintainability. Test names should clearly describe what is being tested, the scenario, and the expected outcome. Good naming makes it easier to understand test failures and serves as documentation for the code's behavior.\n\nTest data management is another critical area. Tests should use consistent, reliable test data that covers various scenarios including edge cases. Data should be isolated between tests to prevent interference, and cleanup mechanisms should ensure tests don't leave residual data.\n\nMaintainability practices include keeping tests DRY (Don't Repeat Yourself) through helper methods and base classes, avoiding test interdependencies, and organizing tests logically. Well-organized tests are easier to maintain and extend over time.\n\nPerformance considerations include running tests in parallel when possible, minimizing expensive setup operations, and focusing on what's important to test rather than achieving 100% coverage at the expense of test quality.\n\nBy following testing best practices, you'll create test suites that are reliable, maintainable, and provide value to your development process.\",\n    \"code\": {\n      \"example\": \"// Example of well-structured test following best practices\nusing Xunit;\n\npublic class UserServiceTests\n{\n    // Use descriptive class names that match the system under test\n    \n    [Fact]\n    public void RegisterUser_WithValidCredentials_CreatesUserAndSendsWelcomeEmail()\n    {\n        // ARRANGE - Clear separation of setup phase\n        var emailServiceMock = new Mock<IEmailService>();\n        var userRepositoryMock = new Mock<IUserRepository>();\n        var userService = new UserService(userRepositoryMock.Object, emailServiceMock.Object);\n        \n        var userDto = new UserRegistrationDto\n        {\n            Email = \\\"test@example.com\\\",\n            Password = \\\"SecurePassword123!\\\",\n            FirstName = \\\"John\\\",\n            LastName = \\\"Doe\\\"\n        };\n        \n        userRepositoryMock.Setup(x => x.GetUserByEmail(userDto.Email))\n                         .Returns((User)null); // User doesn't exist\n        \n        User savedUser = null;\n        userRepositoryMock.Setup(x => x.SaveUser(It.IsAny<User>()))\n                         .Callback<User>(u => savedUser = u)\n                         .Returns(true);\n        \n        // ACT - Clear separation of execution phase\n        var result = userService.RegisterUser(userDto);\n        \n        // ASSERT - Clear separation of verification phase\n        Assert.True(result.Success);\n        Assert.NotNull(savedUser);\n        Assert.Equal(userDto.Email, savedUser.Email);\n        Assert.Equal(userDto.FirstName, savedUser.FirstName);\n        Assert.Equal(userDto.LastName, savedUser.LastName);\n        \n        // Verify interactions with dependencies\n        userRepositoryMock.Verify(x => x.GetUserByEmail(userDto.Email), Times.Once);\n        userRepositoryMock.Verify(x => x.SaveUser(It.IsAny<User>()), Times.Once);\n        emailServiceMock.Verify(x => x.SendWelcomeEmail(userDto.Email), Times.Once);\n    }\n    \n    [Fact]\n    public void RegisterUser_WithExistingEmail_ReturnsFailureResult()\n    {\n        // ARRANGE\n        var emailServiceMock = new Mock<IEmailService>();\n        var userRepositoryMock = new Mock<IUserRepository>();\n        var userService = new UserService(userRepositoryMock.Object, emailServiceMock.Object);\n        \n        var userDto = new UserRegistrationDto\n        {\n            Email = \\\"existing@example.com\\\",\n            Password = \\\"SecurePassword123!\\\",\n            FirstName = \\\"John\\\",\n            LastName = \\\"Doe\\\"\n        };\n        \n        var existingUser = new User { Email = userDto.Email };\n        userRepositoryMock.Setup(x => x.GetUserByEmail(userDto.Email))\n                         .Returns(existingUser); // User already exists\n        \n        // ACT\n        var result = userService.RegisterUser(userDto);\n        \n        // ASSERT\n        Assert.False(result.Success);\n        Assert.Equal(\\\"User already exists\\\", result.ErrorMessage);\n        \n        // Verify no user was saved and no email was sent\n        userRepositoryMock.Verify(x => x.SaveUser(It.IsAny<User>()), Times.Never);\n        emailServiceMock.Verify(x => x.SendWelcomeEmail(It.IsAny<string>()), Times.Never);\n    }\n    \n    [Theory]\n    [InlineData(\\\"\\\")]\n    [InlineData(null)]\n    [InlineData(\\\"invalid-email\\\")]\n    public void RegisterUser_WithInvalidEmail_ReturnsFailureResult(string invalidEmail)\n    {\n        // ARRANGE\n        var emailServiceMock = new Mock<IEmailService>();\n        var userRepositoryMock = new Mock<IUserRepository>();\n        var userService = new UserService(userRepositoryMock.Object, emailServiceMock.Object);\n        \n        var userDto = new UserRegistrationDto\n        {\n            Email = invalidEmail,\n            Password = \\\"SecurePassword123!\\\",\n            FirstName = \\\"John\\\",\n            LastName = \\\"Doe\\\"\n        };\n        \n        // ACT\n        var result = userService.RegisterUser(userDto);\n        \n        // ASSERT\n        Assert.False(result.Success);\n        Assert.Contains(\\\"Invalid email\\\", result.ErrorMessage);\n    }\n}\",\n      \"explanation\": \"This example demonstrates several testing best practices. Test class names clearly indicate what is being tested. Test method names follow the pattern 'MethodName_StateUnderTest_ExpectedBehavior'. The AAA pattern is clearly visible with comments separating each phase. The tests use descriptive variable names and cover both happy path and error scenarios. Mock setups are clear and verification ensures the right interactions occurred. Parameterized tests efficiently cover multiple invalid email cases.\",\n      \"language\": \"csharp\"\n    },\n    \"pitfalls\": [\n      {\n        \"mistake\": \"Using unclear or generic test method names\",\n        \"solution\": \"Use descriptive names that indicate what is being tested, under what conditions, and what is expected\",\n        \"severity\": \"high\"\n      },\n      {\n        \"mistake\": \"Creating tests that are hard to read due to poor structure\",\n        \"solution\": \"Follow the AAA pattern and use clear separation between arrange, act, and assert phases\",\n        \"severity\": \"high\"\n      },\n      {\n        \"mistake\": \"Not cleaning up test data or resources\",\n        \"solution\": \"Use setup and teardown methods or disposables to ensure tests don't leave residual data\",\n        \"severity\": \"medium\"\n      }\n    ],\n    \"exercises\": [\n      {\n        \"title\": \"Refactor Tests to Follow Best Practices\",\n        \"description\": \"Improve existing tests to follow industry best practices for structure and naming.\",\n        \"checkpoints\": [\n          \"Review existing test names and rename them to be more descriptive\",\n          \"Reorganize tests to clearly follow the AAA pattern\",\n          \"Extract common setup code into appropriate locations\",\n          \"Add missing assertions to verify all expected outcomes\",\n          \"Ensure tests are isolated and don't depend on each other\"\n        ]\n      }\n    ],\n    \"next\": [\n      \"testing-fundamentals-lesson-10\"\n    ],\n    \"estimatedMinutes\": 75,\n    \"difficulty\": \"Intermediate\",\n    \"tags\": [\n      \"best-practices\",\n      \"naming\",\n      \"structure\",\n      \"maintainability\",\n      \"aaa-pattern\"\n    ],\n    \"lastUpdated\": \"2025-10-09T10:00:00.000Z\",\n    \"version\": \"1.0.0\"\n  },\n  {\n    \"id\": \"testing-fundamentals-lesson-10\",\n    \"moduleSlug\": \"testing-fundamentals\",\n    \"title\": \"Continuous Integration and Testing\",\n    \"order\": 10,\n    \"objectives\": [\n      \"Integrate automated testing into continuous integration pipelines\",\n      \"Configure test execution in CI environments\",\n      \"Implement quality gates based on test results\",\n      \"Monitor and analyze test results in CI systems\"\n    ],\n    \"intro\": \"Continuous Integration (CI) is a development practice where developers integrate code into a shared repository frequently, typically several times a day. Each integration is verified by an automated build and automated tests to detect integration errors as quickly as possible.\n\nIn a CI environment, automated tests play a crucial role in ensuring code quality and preventing defects from reaching production. Tests are executed automatically whenever code is committed to the repository, providing rapid feedback to developers about the impact of their changes.\n\nEffective CI testing requires careful configuration of test execution environments. Tests should run in consistent, isolated environments that closely match production. This often involves using containers, virtual machines, or cloud-based testing environments to ensure reproducibility.\n\nQuality gates are automated checks that must pass before code can be merged or deployed. These can include minimum test coverage thresholds, successful test execution, code quality metrics, and security scans. Quality gates help maintain code quality standards and prevent problematic code from progressing through the delivery pipeline.\n\nMonitoring and analyzing test results in CI systems is essential for maintaining a healthy test suite. Teams should track test execution times, failure rates, and coverage metrics to identify issues early. Flaky tests (tests that fail intermittently) should be identified and fixed to maintain confidence in the test suite.\n\nCI systems like GitHub Actions, Azure DevOps, Jenkins, and GitLab CI provide features for configuring automated test execution, parallel test running, and detailed reporting. These systems can be configured to run different types of tests at different stages of the pipeline, optimizing feedback time while maintaining thorough testing.\n\nBy integrating testing into CI pipelines, teams can catch defects early, reduce integration issues, and deliver higher quality software more reliably.\",\n    \"code\": {\n      \"example\": \"# GitHub Actions workflow for .NET testing\nname: CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build-and-test:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v3\n    \n    - name: Setup .NET\n      uses: actions/setup-dotnet@v3\n      with:\n        dotnet-version: 8.0.x\n    \n    - name: Restore dependencies\n      run: dotnet restore\n    \n    - name: Build\n      run: dotnet build --no-restore\n    \n    - name: Run unit tests\n      run: dotnet test --no-build --verbosity normal\n    \n    - name: Run integration tests\n      run: dotnet test tests/IntegrationTests --no-build --verbosity normal\n    \n    - name: Collect code coverage\n      run: dotnet test /p:CollectCoverage=true /p:CoverletOutputFormat=opencover\n    \n    - name: Upload coverage to Codecov\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.opencover.xml\n    \n    - name: Check coverage threshold\n      run: |\n        COVERAGE=$(grep -oP 'line-rate=\\\"\\\\K[0-9.]+' ./coverage.opencover.xml)\n        if (( $(echo \\\"$COVERAGE < 0.8\\\" | bc -l) )); then\n          echo \\\"Code coverage is below 80%: $COVERAGE\\\"\n          exit 1\n        fi\n    \n    - name: Run security scans\n      run: dotnet tool run security-scan\n    \n    - name: Generate test reports\n      run: |\n        dotnet test --logger \\\"trx;LogFileName=test-results.trx\\\"\n        dotnet tool run trx2html test-results.trx\n    \n    - name: Archive test results\n      uses: actions/upload-artifact@v3\n      if: always()\n      with:\n        name: test-results\n        path: |\n          **/TestResults/**\n          **/*.trx\n          coverage.opencover.xml\",\n      \"explanation\": \"This GitHub Actions workflow demonstrates CI testing best practices. It runs on both push to main branch and pull requests. The workflow includes steps for restoring dependencies, building the application, running unit and integration tests separately, collecting code coverage, uploading coverage reports, checking coverage thresholds, running security scans, and archiving test results. Quality gates are implemented through coverage thresholds and test execution requirements. The workflow uses appropriate runners and includes error handling with the 'if: always()' condition for artifact upload.\",\n      \"language\": \"yaml\"\n    },\n    \"pitfalls\": [\n      {\n        \"mistake\": \"Allowing failing tests in CI pipelines\",\n        \"solution\": \"Make CI builds fail when tests fail to maintain quality standards and prevent broken code from progressing\",\n        \"severity\": \"high\"\n      },\n      {\n        \"mistake\": \"Not running tests in isolated environments\",\n        \"solution\": \"Use containers or clean environments for each CI run to ensure consistent, reproducible test results\",\n        \"severity\": \"high\"\n      },\n      {\n        \"mistake\": \"Ignoring slow test execution in CI\",\n        \"solution\": \"Optimize test execution time through parallelization, selective testing, and performance improvements\",\n        \"severity\": \"medium\"\n      }\n    ],\n    \"exercises\": [\n      {\n        \"title\": \"Configure a CI Pipeline with Automated Testing\",\n        \"description\": \"Set up a continuous integration pipeline that automatically runs tests and enforces quality gates.\",\n        \"checkpoints\": [\n          \"Configure automated test execution on code commits\",\n          \"Implement separate jobs for unit and integration tests\",\n          \"Set up code coverage collection and reporting\",\n          \"Configure quality gates based on test results and coverage\",\n          \"Implement notifications for test failures and quality gate violations\"\n        ]\n      }\n    ],\n    \"next\": [],\n    \"estimatedMinutes\": 90,\n    \"difficulty\": \"Intermediate\",\n    \"tags\": [\n      \"ci\",\n      \"continuous-integration\",\n      \"github-actions\",\n      \"quality-gates\",\n      \"automation\"\n    ],\n    \"lastUpdated\": \"2025-10-09T10:00:00.000Z\",\n    \"version\": \"1.0.0\"\n  }\n]",
      "explanation": "This example shows a BDD implementation using SpecFlow for a simple Calculator domain. The Gherkin feature file expresses behaviour in business-readable language (Given/When/Then), including a Scenario Outline with tabular Examples. The step definitions bind each step to executable code and delegate work to the Calculator class. The Calculator stores the entered numbers and implements Add (sum of all entered values) and Subtract (first minus second) to satisfy the scenarios. Running these with SpecFlow+xUnit turns the feature into living documentation and automated tests that verify the behaviour end-to-end.",
      "language": "csharp"
    },
    "pitfalls": [
      {
        "mistake": "Writing scenarios that are too technical or too vague",
        "solution": "Work with business stakeholders to write scenarios in clear, business-focused language using concrete examples",
        "severity": "high"
      },
      {
        "mistake": "Creating too many scenario outlines with excessive examples",
        "solution": "Focus on the most important examples that illustrate different behaviors and edge cases",
        "severity": "medium"
      },
      {
        "mistake": "Not maintaining scenarios as the system evolves",
        "solution": "Regularly review and update scenarios to ensure they reflect current system behavior",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement a Shopping Cart Feature with BDD",
        "description": "Create BDD specifications and implementation for a shopping cart feature.",
        "checkpoints": [
          "Write feature files describing shopping cart functionality in business language",
          "Create scenarios for adding, removing, and updating items",
          "Implement step definitions that map to actual code",
          "Handle edge cases like out-of-stock items or quantity limits",
          "Run scenarios as automated tests to validate implementation"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-9"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Intermediate",
    "tags": [
      "bdd",
      "specflow",
      "gherkin",
      "collaboration",
      "specifications"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 9,
    "moduleSlug": "testing-fundamentals",
    "title": "Integration Testing Patterns",
    "order": 9,
    "objectives": [
      "Implement various integration testing patterns for different system boundaries",
      "Use test containers and in-memory databases for isolated integration tests",
      "Apply the testing pyramid concept to balance unit, integration, and end-to-end tests",
      "Create contract tests for API integrations"
    ],
    "intro": "Integration testing is a critical practice that verifies the interactions between different components or systems work correctly together. Unlike unit tests that isolate individual units of code, integration tests exercise the boundaries between components, ensuring that data flows correctly and that integrated systems behave as expected.\n\nThere are several integration testing patterns that address different scenarios and requirements. The classic integration test pattern involves testing components together with their real dependencies, while the test double pattern uses mocks, stubs, or fakes to isolate the system under test. Contract testing focuses on verifying that services adhere to their defined APIs, ensuring compatibility between integrated systems.\n\nTest environments for integration testing require careful consideration to ensure tests are reliable, fast, and isolated. Using test containers, in-memory databases, and dedicated test environments helps create consistent testing conditions while avoiding conflicts between parallel test runs. Proper test data management and cleanup strategies are essential for maintaining test reliability.\n\nThe testing pyramid concept provides guidance on how to balance different types of tests in a test suite. Unit tests form the base of the pyramid due to their speed and precision, while integration tests occupy the middle tier, and end-to-end tests form the narrow top. Understanding this balance helps teams create efficient and effective test suites that provide confidence without excessive execution times.\n\nIn this lesson, you'll learn to implement various integration testing patterns, use modern tools like test containers for reliable integration tests, apply the testing pyramid concept to optimize test suite composition, and create contract tests for API integrations.",
    "code": {
      "example": "// database.test.js - Integration test with in-memory database\nconst { MongoClient } = require('mongodb');\nconst { MongoMemoryServer } = require('mongodb-memory-server');\n\n// Service under test\nconst UserService = {\n  async createUser(db, userData) {\n    const result = await db.collection('users').insertOne({\n      ...userData,\n      createdAt: new Date(),\n      updatedAt: new Date()\n    });\n    return result.ops[0];\n  },\n  \n  async getUserById(db, userId) {\n    return await db.collection('users').findOne({ _id: userId });\n  },\n  \n  async updateUser(db, userId, updateData) {\n    const result = await db.collection('users').findOneAndUpdate(\n      { _id: userId },\n      { $set: { ...updateData, updatedAt: new Date() } },\n      { returnOriginal: false }\n    );\n    return result.value;\n  }\n};\n\n// Integration test suite\ndescribe('UserService Integration Tests', () => {\n  let mongoServer;\n  let connection;\n  let db;\n  \n  beforeAll(async () => {\n    // Start in-memory MongoDB server\n    mongoServer = new MongoMemoryServer();\n    const mongoUri = await mongoServer.getUri();\n    connection = await MongoClient.connect(mongoUri, {\n      useNewUrlParser: true,\n      useUnifiedTopology: true\n    });\n    db = connection.db('testdb');\n  });\n  \n  afterAll(async () => {\n    // Clean up\n    await connection.close();\n    await mongoServer.stop();\n  });\n  \n  beforeEach(async () => {\n    // Clear database before each test\n    await db.collection('users').deleteMany({});\n  });\n  \n  test('should create and retrieve user', async () => {\n    // Arrange\n    const userData = {\n      name: 'John Doe',\n      email: 'john@example.com',\n      age: 30\n    };\n    \n    // Act\n    const createdUser = await UserService.createUser(db, userData);\n    const retrievedUser = await UserService.getUserById(db, createdUser._id);\n    \n    // Assert\n    expect(createdUser).toMatchObject(userData);\n    expect(retrievedUser).toMatchObject(userData);\n    expect(retrievedUser._id).toEqual(createdUser._id);\n    expect(retrievedUser.createdAt).toBeInstanceOf(Date);\n  });\n  \n  test('should update user', async () => {\n    // Arrange\n    const userData = { name: 'John Doe', email: 'john@example.com' };\n    const createdUser = await UserService.createUser(db, userData);\n    \n    // Act\n    const updatedUser = await UserService.updateUser(db, createdUser._id, {\n      name: 'Jane Doe',\n      age: 25\n    });\n    \n    // Assert\n    expect(updatedUser.name).toBe('Jane Doe');\n    expect(updatedUser.age).toBe(25);\n    expect(updatedUser.email).toBe('john@example.com'); // Unchanged\n    expect(updatedUser.updatedAt).toBeInstanceOf(Date);\n  });\n});\n\n// api-contract.test.js - Contract testing example\nconst axios = require('axios');\n\n// Mock external API service for contract testing\njest.mock('axios');\n\n// Service that depends on external API\nconst WeatherService = {\n  async getWeather(city) {\n    try {\n      const response = await axios.get(`https://api.weather.com/v1/weather?city=${city}`);\n      return {\n        city: response.data.city,\n        temperature: response.data.temperature,\n        condition: response.data.condition,\n        timestamp: new Date()\n      };\n    } catch (error) {\n      if (error.response && error.response.status === 404) {\n        throw new Error('City not found');\n      }\n      throw new Error('Weather service unavailable');\n    }\n  }\n};\n\n// Contract tests\ndescribe('WeatherService Contract Tests', () => {\n  beforeEach(() => {\n    axios.get.mockReset();\n  });\n  \n  test('should return weather data for valid city', async () => {\n    // Arrange\n    const mockResponse = {\n      data: {\n        city: 'London',\n        temperature: 15,\n        condition: 'Cloudy'\n      },\n      status: 200\n    };\n    axios.get.mockResolvedValue(mockResponse);\n    \n    // Act\n    const weather = await WeatherService.getWeather('London');\n    \n    // Assert\n    expect(weather).toEqual({\n      city: 'London',\n      temperature: 15,\n      condition: 'Cloudy',\n      timestamp: expect.any(Date)\n    });\n    expect(axios.get).toHaveBeenCalledWith('https://api.weather.com/v1/weather?city=London');\n  });\n  \n  test('should throw error for non-existent city', async () => {\n    // Arrange\n    const mockError = {\n      response: {\n        status: 404,\n        data: { error: 'City not found' }\n      }\n    };\n    axios.get.mockRejectedValue(mockError);\n    \n    // Act & Assert\n    await expect(WeatherService.getWeather('NonExistentCity'))\n      .rejects\n      .toThrow('City not found');\n  });\n});\n\n// database-integration.test.js - Database integration patterns\nconst sqlite3 = require('sqlite3').verbose();\nconst { open } = require('sqlite');\n\n// Repository pattern for database integration\nclass UserRepository {\n  constructor(db) {\n    this.db = db;\n  }\n  \n  async create(user) {\n    const result = await this.db.run(\n      'INSERT INTO users (name, email, created_at) VALUES (?, ?, ?)',\n      [user.name, user.email, new Date().toISOString()]\n    );\n    return { id: result.lastID, ...user };\n  }\n  \n  async findById(id) {\n    return await this.db.get('SELECT * FROM users WHERE id = ?', [id]);\n  }\n  \n  async findAll() {\n    return await this.db.all('SELECT * FROM users ORDER BY created_at DESC');\n  }\n  \n  async update(id, updates) {\n    const setClause = Object.keys(updates)\n      .map(key => `${key} = ?`)\n      .join(', ');\n    const values = [...Object.values(updates), id];\n    \n    await this.db.run(\n      `UPDATE users SET ${setClause} WHERE id = ?`,\n      values\n    );\n    \n    return await this.findById(id);\n  }\n  \n  async delete(id) {\n    return await this.db.run('DELETE FROM users WHERE id = ?', [id]);\n  }\n}\n\n// Integration tests with SQLite\ndescribe('UserRepository Integration Tests', () => {\n  let db;\n  let userRepository;\n  \n  beforeAll(async () => {\n    // Use in-memory SQLite database\n    db = await open({\n      filename: ':memory:',\n      driver: sqlite3.Database\n    });\n    \n    // Create table\n    await db.exec(`\n      CREATE TABLE users (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        name TEXT NOT NULL,\n        email TEXT UNIQUE NOT NULL,\n        created_at TEXT NOT NULL\n      )\n    `);\n    \n    userRepository = new UserRepository(db);\n  });\n  \n  afterAll(async () => {\n    await db.close();\n  });\n  \n  test('should create and retrieve user', async () => {\n    // Arrange\n    const userData = {\n      name: 'Alice Smith',\n      email: 'alice@example.com'\n    };\n    \n    // Act\n    const createdUser = await userRepository.create(userData);\n    const retrievedUser = await userRepository.findById(createdUser.id);\n    \n    // Assert\n    expect(createdUser.id).toBeGreaterThan(0);\n    expect(createdUser.name).toBe(userData.name);\n    expect(createdUser.email).toBe(userData.email);\n    expect(retrievedUser).toEqual(expect.objectContaining({\n      id: createdUser.id,\n      name: userData.name,\n      email: userData.email\n    }));\n  });\n});",
      "explanation": "This example demonstrates several integration testing patterns:\n\n1. **In-Memory Database Testing**: Using MongoMemoryServer for MongoDB integration tests\n2. **Database Integration Patterns**: Repository pattern with SQLite for structured database tests\n3. **Contract Testing**: Verifying API contracts with external services\n4. **Test Isolation**: Proper setup and teardown for isolated test runs\n5. **Data Management**: Test data creation and cleanup strategies\n\nKey concepts illustrated:\n- Integration test setup with beforeAll/afterAll hooks\n- Database connection management\n- Test data isolation\n- API contract verification\n- Repository pattern implementation\n- Error handling in integration tests\n\nThe tests verify:\n- User creation and retrieval workflows\n- Data persistence and integrity\n- Error handling for various scenarios\n- API contract compliance\n- Database operation correctness",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Not properly isolating integration tests leading to test flakiness",
        "solution": "Use dedicated test databases, in-memory databases, or test containers with proper cleanup between tests",
        "severity": "high"
      },
      {
        "mistake": "Making integration tests too slow by testing too much in each test",
        "solution": "Focus each integration test on a specific integration point and keep test data minimal",
        "severity": "high"
      },
      {
        "mistake": "Skipping integration tests in CI/CD pipelines due to complexity",
        "solution": "Use containerization tools like Docker and test containers to make integration tests portable and reliable",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement Integration Tests for a REST API Service",
        "description": "Create comprehensive integration tests for a REST API service with database integration.",
        "checkpoints": [
          "Set up in-memory database for isolated integration tests",
          "Implement repository pattern tests for CRUD operations",
          "Create contract tests for external API dependencies",
          "Apply proper test data management and cleanup strategies",
          "Use test containers for consistent test environments"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-10"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Advanced",
    "tags": [
      "Integration Testing",
      "Test Patterns",
      "Database",
      "API",
      "Contract Testing"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 10,
    "moduleSlug": "testing-fundamentals",
    "title": "Mocking Best Practices",
    "order": 10,
    "objectives": [
      "Apply mocking techniques effectively to isolate units of code during testing",
      "Choose appropriate test doubles (mocks, stubs, fakes, spies) for different scenarios",
      "Implement mocking frameworks properly to avoid brittle tests",
      "Use dependency injection to enable effective mocking strategies"
    ],
    "intro": "Mocking is a powerful technique in software testing that allows developers to isolate units of code by replacing dependencies with controlled substitutes. Effective mocking enables focused unit tests that verify specific behaviors without being affected by external factors like network calls, database operations, or third-party services.\n\nThere are several types of test doubles, each serving different purposes in testing scenarios. Stubs provide canned responses to method calls without verifying interactions, making them ideal for setting up test conditions. Mocks not only provide responses but also verify that specific methods were called with expected parameters, ensuring behavioral correctness. Fakes are simplified implementations of dependencies that behave like the real thing but are designed for testing. Spies record information about how they were used, allowing tests to verify interactions after the fact.\n\nChoosing the right type of test double is crucial for creating effective tests. Over-mocking can lead to brittle tests that break when implementation details change, while under-mocking can result in tests that are slow, unreliable, or difficult to set up. Understanding when to use each type of test double helps create maintainable test suites that provide confidence without excessive maintenance overhead.\n\nDependency injection is a fundamental technique that enables effective mocking by allowing dependencies to be provided externally rather than being hardcoded within a class. Proper dependency injection patterns make it easy to substitute real implementations with test doubles during testing while maintaining clean, loosely-coupled code in production.\n\nIn this lesson, you'll learn to apply mocking techniques effectively for unit testing, choose appropriate test doubles for different scenarios, implement mocking frameworks properly to avoid brittle tests, and use dependency injection to enable flexible testing strategies.",
    "code": {
      "example": "// user-service.test.js - Mocking best practices\nconst sinon = require('sinon');\nconst { expect } = require('chai');\n\n// Service under test\nclass UserService {\n  constructor(userRepository, emailService, logger) {\n    this.userRepository = userRepository;\n    this.emailService = emailService;\n    this.logger = logger;\n  }\n  \n  async createUser(userData) {\n    try {\n      // Validate input\n      if (!userData.email) {\n        throw new Error('Email is required');\n      }\n      \n      // Check if user already exists\n      const existingUser = await this.userRepository.findByEmail(userData.email);\n      if (existingUser) {\n        throw new Error('User already exists');\n      }\n      \n      // Create user\n      const user = await this.userRepository.create({\n        ...userData,\n        createdAt: new Date()\n      });\n      \n      // Send welcome email\n      await this.emailService.sendWelcomeEmail(user.email, user.name);\n      \n      // Log success\n      this.logger.info(`User created: ${user.id}`);\n      \n      return user;\n    } catch (error) {\n      this.logger.error(`Failed to create user: ${error.message}`);\n      throw error;\n    }\n  }\n  \n  async getUserStats(userId) {\n    const user = await this.userRepository.findById(userId);\n    if (!user) {\n      throw new Error('User not found');\n    }\n    \n    const stats = await this.userRepository.getUserStats(userId);\n    return {\n      ...user,\n      stats\n    };\n  }\n}\n\n// Test suite with proper mocking\ndescribe('UserService', () => {\n  let userService;\n  let userRepositoryMock;\n  let emailServiceMock;\n  let loggerMock;\n  \n  beforeEach(() => {\n    // Create mocks for dependencies\n    userRepositoryMock = {\n      findByEmail: sinon.stub(),\n      create: sinon.stub(),\n      findById: sinon.stub(),\n      getUserStats: sinon.stub()\n    };\n    \n    emailServiceMock = {\n      sendWelcomeEmail: sinon.stub()\n    };\n    \n    loggerMock = {\n      info: sinon.stub(),\n      error: sinon.stub()\n    };\n    \n    // Create service with mocked dependencies\n    userService = new UserService(userRepositoryMock, emailServiceMock, loggerMock);\n  });\n  \n  afterEach(() => {\n    // Restore mocks after each test\n    sinon.restore();\n  });\n  \n  describe('createUser', () => {\n    test('should create user successfully', async () => {\n      // Arrange\n      const userData = { name: 'John Doe', email: 'john@example.com' };\n      const createdUser = { id: 1, ...userData, createdAt: new Date() };\n      \n      // Set up mocks\n      userRepositoryMock.findByEmail.resolves(null); // No existing user\n      userRepositoryMock.create.resolves(createdUser);\n      emailServiceMock.sendWelcomeEmail.resolves();\n      \n      // Act\n      const result = await userService.createUser(userData);\n      \n      // Assert\n      expect(result).toEqual(createdUser);\n      expect(userRepositoryMock.findByEmail.calledOnceWith('john@example.com')).toBe(true);\n      expect(userRepositoryMock.create.calledOnce).toBe(true);\n      expect(emailServiceMock.sendWelcomeEmail.calledOnceWith('john@example.com', 'John Doe')).toBe(true);\n      expect(loggerMock.info.calledOnce).toBe(true);\n    });\n    \n    test('should throw error if email already exists', async () => {\n      // Arrange\n      const userData = { name: 'John Doe', email: 'john@example.com' };\n      const existingUser = { id: 1, ...userData };\n      \n      // Set up mock\n      userRepositoryMock.findByEmail.resolves(existingUser);\n      \n      // Act & Assert\n      await expect(userService.createUser(userData))\n        .rejects\n        .toThrow('User already exists');\n      \n      expect(userRepositoryMock.findByEmail.calledOnce).toBe(true);\n      expect(userRepositoryMock.create.notCalled).toBe(true);\n      expect(emailServiceMock.sendWelcomeEmail.notCalled).toBe(true);\n      expect(loggerMock.error.calledOnce).toBe(true);\n    });\n    \n    test('should throw error if email is missing', async () => {\n      // Act & Assert\n      await expect(userService.createUser({ name: 'John Doe' }))\n        .rejects\n        .toThrow('Email is required');\n      \n      // Verify no interactions with dependencies\n      expect(userRepositoryMock.findByEmail.notCalled).toBe(true);\n      expect(userRepositoryMock.create.notCalled).toBe(true);\n      expect(emailServiceMock.sendWelcomeEmail.notCalled).toBe(true);\n      expect(loggerMock.error.calledOnce).toBe(true);\n    });\n  });\n  \n  describe('getUserStats', () => {\n    test('should return user with stats', async () => {\n      // Arrange\n      const userId = 1;\n      const user = { id: userId, name: 'John Doe', email: 'john@example.com' };\n      const stats = { posts: 10, followers: 100 };\n      \n      // Set up mocks\n      userRepositoryMock.findById.resolves(user);\n      userRepositoryMock.getUserStats.resolves(stats);\n      \n      // Act\n      const result = await userService.getUserStats(userId);\n      \n      // Assert\n      expect(result).toEqual({ ...user, stats });\n      expect(userRepositoryMock.findById.calledOnceWith(userId)).toBe(true);\n      expect(userRepositoryMock.getUserStats.calledOnceWith(userId)).toBe(true);\n    });\n    \n    test('should throw error if user not found', async () => {\n      // Arrange\n      const userId = 999;\n      userRepositoryMock.findById.resolves(null);\n      \n      // Act & Assert\n      await expect(userService.getUserStats(userId))\n        .rejects\n        .toThrow('User not found');\n      \n      expect(userRepositoryMock.findById.calledOnceWith(userId)).toBe(true);\n      expect(userRepositoryMock.getUserStats.notCalled).toBe(true);\n    });\n  });\n});\n\n// http-client.test.js - Mocking HTTP clients\nconst nock = require('nock');\n\n// Service that makes HTTP requests\nclass WeatherService {\n  constructor(httpClient) {\n    this.httpClient = httpClient;\n  }\n  \n  async getCurrentWeather(city) {\n    try {\n      const response = await this.httpClient.get(`https://api.weather.com/v1/current?city=${city}`);\n      return {\n        city: response.data.city,\n        temperature: response.data.temperature,\n        condition: response.data.condition,\n        timestamp: new Date()\n      };\n    } catch (error) {\n      if (error.response && error.response.status === 404) {\n        throw new Error('City not found');\n      }\n      throw new Error('Weather service unavailable');\n    }\n  }\n}\n\n// Test with HTTP mocking\ndescribe('WeatherService', () => {\n  let weatherService;\n  \n  beforeEach(() => {\n    weatherService = new WeatherService({\n      get: (url) => fetch(url).then(res => res.json())\n    });\n    \n    // Mock HTTP requests\n    nock('https://api.weather.com')\n      .get('/v1/current?city=London')\n      .reply(200, {\n        city: 'London',\n        temperature: 15,\n        condition: 'Cloudy'\n      });\n      \n    nock('https://api.weather.com')\n      .get('/v1/current?city=NotFound')\n      .reply(404, { error: 'City not found' });\n  });\n  \n  afterEach(() => {\n    // Clean up HTTP mocks\n    nock.cleanAll();\n  });\n  \n  test('should return weather data for valid city', async () => {\n    // Act\n    const weather = await weatherService.getCurrentWeather('London');\n    \n    // Assert\n    expect(weather.city).toBe('London');\n    expect(weather.temperature).toBe(15);\n    expect(weather.condition).toBe('Cloudy');\n    expect(weather.timestamp).toBeInstanceOf(Date);\n  });\n  \n  test('should throw error for non-existent city', async () => {\n    // Act & Assert\n    await expect(weatherService.getCurrentWeather('NotFound'))\n      .rejects\n      .toThrow('City not found');\n  });\n});",
      "explanation": "This example demonstrates mocking best practices including:\n\n1. **Dependency Injection**: UserService accepts dependencies through constructor\n2. **Appropriate Test Doubles**: Using stubs for setup, mocks for verification\n3. **Focused Unit Tests**: Isolating the system under test from real dependencies\n4. **Comprehensive Test Scenarios**: Testing success, error, and edge cases\n5. **Proper Mock Cleanup**: Restoring mocks after each test\n6. **HTTP Client Mocking**: Using nock for HTTP request mocking\n\nKey concepts illustrated:\n- Mock setup and verification patterns\n- Test data arrangement\n- Behavior verification\n- Error condition testing\n- Dependency injection for testability\n- HTTP request mocking\n\nThe tests verify:\n- User creation workflow with email sending\n- Duplicate user detection\n- Input validation\n- Error handling and logging\n- User statistics retrieval\n- HTTP client interaction",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Over-mocking every dependency leading to brittle tests that break with implementation changes",
        "solution": "Mock only the dependencies that are essential for isolating the unit under test, focusing on external services and complex collaborators",
        "severity": "high"
      },
      {
        "mistake": "Not using dependency injection making it difficult to substitute real implementations with mocks",
        "solution": "Design classes to accept dependencies through constructors or setter methods to enable flexible testing",
        "severity": "high"
      },
      {
        "mistake": "Verifying implementation details instead of behavior",
        "solution": "Focus on testing what the code does rather than how it does it, verifying outcomes rather than specific method calls",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement Comprehensive Mocking Strategies",
        "description": "Create unit tests with effective mocking for a service with multiple dependencies.",
        "checkpoints": [
          "Implement dependency injection to enable testability",
          "Create appropriate test doubles (stubs, mocks, fakes) for different scenarios",
          "Write focused unit tests that verify behavior without testing implementation details",
          "Mock external services like HTTP clients and databases effectively",
          "Apply proper test setup and teardown with mock cleanup"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-11"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Advanced",
    "tags": [
      "Mocking",
      "Test Doubles",
      "Unit Testing",
      "Dependency Injection",
      "Sinon"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 11,
    "moduleSlug": "testing-fundamentals",
    "title": "Test Data Management",
    "order": 11,
    "objectives": [
      "Implement effective test data strategies for different types of tests",
      "Use factory patterns and data builders for consistent test data creation",
      "Apply data anonymization techniques for testing with production data",
      "Manage test data lifecycle with proper setup and teardown procedures"
    ],
    "intro": "Test data management is a critical aspect of software testing that involves creating, maintaining, and organizing data used in tests. Proper test data management ensures tests are reliable, repeatable, and representative of real-world scenarios while maintaining security and compliance requirements.\n\nEffective test data strategies vary depending on the type of tests being performed. Unit tests typically require minimal, focused data sets that exercise specific code paths, while integration tests need more comprehensive data that represents realistic integration scenarios. End-to-end tests often require complex data sets that mirror production environments, including relationships between different data entities.\n\nFactory patterns and data builders provide structured approaches to creating consistent, maintainable test data. These patterns help avoid duplication, ensure data consistency across tests, and make it easier to modify test data when requirements change. Data factories can generate realistic test data with appropriate variations and edge cases.\n\nWhen using production data for testing, data anonymization techniques are essential for protecting sensitive information and maintaining compliance with privacy regulations. Techniques include data masking, pseudonymization, and synthetic data generation that preserve data characteristics while removing personally identifiable information.\n\nTest data lifecycle management involves proper setup and teardown procedures to ensure tests are isolated and don't interfere with each other. This includes creating fresh data for each test, cleaning up after tests complete, and managing shared test data resources efficiently. Database transactions and savepoints can be used to roll back changes after tests.\n\nIn this lesson, you'll learn to implement effective test data strategies for different test types, use factory patterns for consistent data creation, apply data anonymization techniques for security, and manage test data lifecycle with proper setup and cleanup procedures.",
    "code": {
      "example": "// test-data-factory.js - Test data factory patterns\n\nclass UserFactory {\n  static counter = 0;\n  \n  static create(overrides = {}) {\n    UserFactory.counter++;\n    return {\n      id: overrides.id || UserFactory.counter,\n      name: overrides.name || `User ${UserFactory.counter}`,\n      email: overrides.email || `user${UserFactory.counter}@example.com`,\n      age: overrides.age || Math.floor(Math.random() * 50) + 18,\n      role: overrides.role || 'user',\n      createdAt: overrides.createdAt || new Date(),\n      ...overrides\n    };\n  }\n  \n  static createAdmin(overrides = {}) {\n    return UserFactory.create({\n      role: 'admin',\n      ...overrides\n    });\n  }\n  \n  static createMany(count, overrides = {}) {\n    return Array.from({ length: count }, (_, i) =>\n      UserFactory.create({\n        ...overrides,\n        id: overrides.id || UserFactory.counter + i + 1\n      })\n    );\n  }\n}\n\nclass ProductFactory {\n  static counter = 0;\n  \n  static create(overrides = {}) {\n    ProductFactory.counter++;\n    return {\n      id: overrides.id || ProductFactory.counter,\n      name: overrides.name || `Product ${ProductFactory.counter}`,\n      price: overrides.price || (Math.random() * 100).toFixed(2),\n      category: overrides.category || ['Electronics', 'Books', 'Clothing'][Math.floor(Math.random() * 3)],\n      inStock: overrides.inStock || Math.random() > 0.2, // 80% chance of being in stock\n      createdAt: overrides.createdAt || new Date(),\n      ...overrides\n    };\n  }\n  \n  static createMany(count, overrides = {}) {\n    return Array.from({ length: count }, (_, i) =>\n      ProductFactory.create({\n        ...overrides,\n        id: overrides.id || ProductFactory.counter + i + 1\n      })\n    );\n  }\n}\n\nclass OrderFactory {\n  static counter = 0;\n  \n  static create(overrides = {}) {\n    OrderFactory.counter++;\n    return {\n      id: overrides.id || OrderFactory.counter,\n      userId: overrides.userId || Math.floor(Math.random() * 100) + 1,\n      items: overrides.items || [],\n      total: overrides.total || 0,\n      status: overrides.status || 'pending',\n      createdAt: overrides.createdAt || new Date(),\n      ...overrides\n    };\n  }\n  \n  static createWithItems(user, products, itemCount = 3) {\n    const selectedProducts = [];\n    let total = 0;\n    \n    for (let i = 0; i < itemCount; i++) {\n      const product = products[Math.floor(Math.random() * products.length)];\n      const quantity = Math.floor(Math.random() * 3) + 1;\n      const itemTotal = (parseFloat(product.price) * quantity);\n      \n      selectedProducts.push({\n        productId: product.id,\n        name: product.name,\n        price: product.price,\n        quantity,\n        total: itemTotal.toFixed(2)\n      });\n      \n      total += itemTotal;\n    }\n    \n    return OrderFactory.create({\n      userId: user.id,\n      items: selectedProducts,\n      total: total.toFixed(2)\n    });\n  }\n}\n\n// database-test-setup.js - Test data lifecycle management\nconst { MongoClient } = require('mongodb');\nconst { MongoMemoryServer } = require('mongodb-memory-server');\n\n// Test database manager\nclass TestDatabaseManager {\n  constructor() {\n    this.mongoServer = null;\n    this.connection = null;\n    this.db = null;\n  }\n  \n  async setup() {\n    // Start in-memory MongoDB server\n    this.mongoServer = new MongoMemoryServer();\n    const mongoUri = await this.mongoServer.getUri();\n    this.connection = await MongoClient.connect(mongoUri, {\n      useNewUrlParser: true,\n      useUnifiedTopology: true\n    });\n    this.db = this.connection.db('testdb');\n    \n    // Create collections\n    await this.db.createCollection('users');\n    await this.db.createCollection('products');\n    await this.db.createCollection('orders');\n    \n    return this.db;\n  }\n  \n  async teardown() {\n    if (this.connection) {\n      await this.connection.close();\n    }\n    if (this.mongoServer) {\n      await this.mongoServer.stop();\n    }\n  }\n  \n  async clearData() {\n    if (this.db) {\n      await this.db.collection('users').deleteMany({});\n      await this.db.collection('products').deleteMany({});\n      await this.db.collection('orders').deleteMany({});\n    }\n  }\n  \n  async seedData() {\n    // Create test users\n    const users = UserFactory.createMany(5);\n    await this.db.collection('users').insertMany(users);\n    \n    // Create test products\n    const products = ProductFactory.createMany(10);\n    await this.db.collection('products').insertMany(products);\n    \n    // Create test orders\n    const orders = users.slice(0, 3).map(user =>\n      OrderFactory.createWithItems(user, products, 2)\n    );\n    await this.db.collection('orders').insertMany(orders);\n    \n    return { users, products, orders };\n  }\n}\n\n// test-data-anonymization.js - Data anonymization techniques\n\nclass DataAnonymizer {\n  static anonymizeUserData(user) {\n    return {\n      ...user,\n      name: this.maskName(user.name),\n      email: this.maskEmail(user.email),\n      phone: user.phone ? this.maskPhone(user.phone) : undefined,\n      address: user.address ? this.maskAddress(user.address) : undefined\n    };\n  }\n  \n  static maskName(name) {\n    if (!name) return name;\n    const parts = name.split(' ');\n    return parts.map((part, index) => {\n      if (index === 0) {\n        // Mask first name but keep first letter\n        return part.charAt(0) + '*'.repeat(Math.max(0, part.length - 1));\n      } else {\n        // Keep last name as is for identification\n        return part;\n      }\n    }).join(' ');\n  }\n  \n  static maskEmail(email) {\n    if (!email) return email;\n    const [localPart, domain] = email.split('@');\n    if (localPart.length <= 2) {\n      return '*@' + domain;\n    }\n    return localPart.charAt(0) + '*'.repeat(localPart.length - 2) + localPart.charAt(localPart.length - 1) + '@' + domain;\n  }\n  \n  static maskPhone(phone) {\n    if (!phone) return phone;\n    // Keep last 4 digits, mask the rest\n    return phone.replace(/(\\d)(?=\\d{4})/g, '*');\n  }\n  \n  static maskAddress(address) {\n    if (!address) return address;\n    // Keep city and country, mask street\n    return address.replace(/^(.*?),/, '***,');\n  }\n  \n  static generateSyntheticData(template, count) {\n    return Array.from({ length: count }, (_, i) => ({\n      ...template,\n      id: i + 1,\n      createdAt: new Date(Date.now() - Math.random() * 365 * 24 * 60 * 60 * 1000) // Random date within last year\n    }));\n  }\n}\n\n// test-data-factory.test.js - Using test data factories\ndescribe('TestDataFactories', () => {\n  let dbManager;\n  \n  beforeAll(async () => {\n    dbManager = new TestDatabaseManager();\n    await dbManager.setup();\n  });\n  \n  afterAll(async () => {\n    await dbManager.teardown();\n  });\n  \n  beforeEach(async () => {\n    await dbManager.clearData();\n  });\n  \n  test('should create users with factory', async () => {\n    // Arrange\n    const userData = { name: 'John Doe', email: 'john@example.com', age: 30 };\n    \n    // Act\n    const user = UserFactory.create(userData);\n    \n    // Assert\n    expect(user).toEqual(expect.objectContaining({\n      name: 'John Doe',\n      email: 'john@example.com',\n      age: 30,\n      id: expect.any(Number),\n      createdAt: expect.any(Date)\n    }));\n  });\n  \n  test('should create admin user', async () => {\n    // Act\n    const admin = UserFactory.createAdmin({ name: 'Admin User' });\n    \n    // Assert\n    expect(admin.role).toBe('admin');\n    expect(admin.name).toBe('Admin User');\n  });\n  \n  test('should anonymize user data', async () => {\n    // Arrange\n    const user = UserFactory.create({\n      name: 'John Doe',\n      email: 'john.doe@example.com',\n      phone: '123-456-7890'\n    });\n    \n    // Act\n    const anonymized = DataAnonymizer.anonymizeUserData(user);\n\n    // Assert\n    expect(anonymized.name).toBe('J*** Doe');\n    expect(anonymized.email).toBe('j********e@example.com');\n    expect(anonymized.phone).toBe('***-***-7890');\n  });\n  \n  test('should manage test data lifecycle', async () => {\n    // Act\n    const { users, products, orders } = await dbManager.seedData();\n    \n    // Assert\n    expect(users).toHaveLength(5);\n    expect(products).toHaveLength(10);\n    expect(orders).toHaveLength(3);\n    \n    // Verify data was inserted\n    const userCount = await dbManager.db.collection('users').countDocuments();\n    const productCount = await dbManager.db.collection('products').countDocuments();\n    const orderCount = await dbManager.db.collection('orders').countDocuments();\n    \n    expect(userCount).toBe(5);\n    expect(productCount).toBe(10);\n    expect(orderCount).toBe(3);\n  });\n});",
      "explanation": "This example demonstrates comprehensive test data management techniques including:\n\n1. **Factory Patterns**: UserFactory, ProductFactory, and OrderFactory for consistent test data creation\n2. **Data Anonymization**: Methods to mask sensitive information while preserving data structure\n3. **Test Data Lifecycle**: TestDatabaseManager for setup, teardown, and data management\n4. **Synthetic Data Generation**: Creating realistic test data without using real user information\n\nKey concepts illustrated:\n- Factory pattern implementation\n- Data anonymization techniques\n- Test database management\n- Seeding and cleanup strategies\n- Relationship-based data creation\n\nThe tests verify:\n- Factory creation of different entity types\n- Data anonymization effectiveness\n- Test data lifecycle management\n- Database seeding and verification\n- Consistent data generation",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Using production data directly in tests without proper anonymization",
        "solution": "Implement data anonymization techniques and use synthetic data generators for test environments",
        "severity": "high"
      },
      {
        "mistake": "Creating inconsistent test data across tests leading to unreliable test results",
        "solution": "Use factory patterns and data builders to ensure consistent, reproducible test data",
        "severity": "high"
      },
      {
        "mistake": "Not properly cleaning up test data leading to test interference and resource waste",
        "solution": "Implement proper setup and teardown procedures with transaction rollbacks or data deletion",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement Comprehensive Test Data Management",
        "description": "Create a complete test data management system with factories, anonymization, and lifecycle management.",
        "checkpoints": [
          "Implement factory patterns for different entity types in your application",
          "Create data anonymization functions for sensitive information",
          "Build a test database manager with setup, teardown, and cleanup procedures",
          "Generate synthetic test data that represents realistic scenarios",
          "Apply proper test data lifecycle management in your test suites"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-12"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Advanced",
    "tags": [
      "Test Data",
      "Factory Pattern",
      "Data Anonymization",
      "Lifecycle Management",
      "Synthetic Data"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 12,
    "moduleSlug": "testing-fundamentals",
    "title": "Behavior-Driven Development",
    "order": 12,
    "objectives": [
      "Write executable specifications using Gherkin syntax for BDD",
      "Implement step definitions that translate business language to code",
      "Apply the Given-When-Then pattern for clear scenario descriptions",
      "Collaborate effectively with stakeholders using BDD practices"
    ],
    "intro": "Behavior-Driven Development (BDD) is a collaborative approach to software development that bridges the gap between business requirements and technical implementation. BDD extends Test-Driven Development by focusing on behavior and using a common language that business stakeholders, developers, and testers can all understand.\n\nThe core of BDD is the use of executable specifications written in a structured format called Gherkin. Gherkin uses a Given-When-Then syntax that describes scenarios in terms of preconditions (Given), actions (When), and expected outcomes (Then). This format makes it easy for non-technical stakeholders to understand what the software should do while providing a clear structure for automated tests.\n\nThe Given-When-Then pattern provides a consistent way to describe scenarios that helps ensure all perspectives are considered. Given sections establish the context and preconditions, When sections describe the action or event being tested, and Then sections specify the expected outcomes. This pattern encourages thinking about edge cases and alternative scenarios.\n\nEffective BDD requires collaboration between all stakeholders in the development process. Business analysts work with developers and testers to create scenarios that accurately reflect business requirements. This collaboration helps identify misunderstandings early and ensures that the software meets real business needs rather than just technical specifications.\n\nImplementation of BDD involves writing step definitions that translate the natural language scenarios into executable code. These step definitions serve as the bridge between business language and technical implementation, making tests both readable and functional. Good step definitions are reusable, maintainable, and clearly express the intent of the scenarios they implement.\n\nIn this lesson, you'll learn to write executable specifications using Gherkin syntax, implement step definitions that connect business language to code, apply the Given-When-Then pattern for clear scenario descriptions, and collaborate effectively with stakeholders using BDD practices.",
    "code": {
      "example": "// features/user-registration.feature - BDD feature file\n/*\nFeature: User Registration\n  As a new user\n  I want to register for the application\n  So that I can access my account\n\n  Background:\n    Given the registration page is open\n\n  Scenario: Successful user registration\n    Given I am on the registration page\n    When I fill in the registration form with valid details\n      | name     | email              | password  |\n      | John Doe | john@example.com   | secret123 |\n    And I submit the registration form\n    Then I should see a welcome message\n    And I should be logged in automatically\n\n  Scenario: Registration with invalid email\n    Given I am on the registration page\n    When I fill in the registration form with an invalid email\n      | name     | email        | password  |\n      | John Doe | invalid-email| secret123 |\n    And I submit the registration form\n    Then I should see an email validation error\n    And I should remain on the registration page\n\n  Scenario Outline: Registration with various password strengths\n    Given I am on the registration page\n    When I fill in the registration form with password \"<password>\"\n    And I submit the registration form\n    Then I should see \"<result>\"\n\n    Examples:\n      | password    | result                     |\n      | 12345       | password strength warning  |\n      | secret123   | successful registration    |\n      | verylongpassword123!@# | successful registration |\n*/\n\n// step-definitions/user-registration.steps.js - Step definitions\nconst { Given, When, Then } = require('@cucumber/cucumber');\nconst { expect } = require('chai');\nconst RegistrationPage = require('../pages/registration-page');\nconst DashboardPage = require('../pages/dashboard-page');\n\n// Page objects\nlet registrationPage;\nlet dashboardPage;\n\nGiven('the registration page is open', async function() {\n  registrationPage = new RegistrationPage();\n  await registrationPage.open();\n});\n\nGiven('I am on the registration page', async function() {\n  // This step is similar to the background step\n  registrationPage = new RegistrationPage();\n  await registrationPage.open();\n});\n\nWhen('I fill in the registration form with valid details', async function(dataTable) {\n  const userData = dataTable.rowsHash();\n  await registrationPage.fillForm(userData);\n});\n\nWhen('I fill in the registration form with an invalid email', async function(dataTable) {\n  const userData = dataTable.rowsHash();\n  await registrationPage.fillForm(userData);\n});\n\nWhen('I fill in the registration form with password {string}', async function(password) {\n  await registrationPage.fillForm({\n    name: 'Test User',\n    email: 'test@example.com',\n    password: password\n  });\n});\n\nWhen('I submit the registration form', async function() {\n  await registrationPage.submit();\n});\n\nThen('I should see a welcome message', async function() {\n  const welcomeMessage = await registrationPage.getWelcomeMessage();\n  expect(welcomeMessage).to.include('Welcome');\n});\n\nThen('I should be logged in automatically', async function() {\n  dashboardPage = new DashboardPage();\n  const isLoggedIn = await dashboardPage.isLoggedIn();\n  expect(isLoggedIn).to.be.true;\n});\n\nThen('I should see an email validation error', async function() {\n  const errorMessage = await registrationPage.getEmailError();\n  expect(errorMessage).to.include('valid email');\n});\n\nThen('I should remain on the registration page', async function() {\n  const currentUrl = await registrationPage.getCurrentUrl();\n  expect(currentUrl).to.include('/register');\n});\n\nThen('I should see {string}', async function(expectedMessage) {\n  const pageContent = await registrationPage.getPageContent();\n  expect(pageContent).to.include(expectedMessage);\n});\n\n// pages/registration-page.js - Page object for registration\nclass RegistrationPage {\n  constructor() {\n    // In a real implementation, this would interact with a browser\n    // using tools like Puppeteer or Selenium\n    this.url = 'http://localhost:3000/register';\n    this.userData = {};\n  }\n  \n  async open() {\n    // Simulate opening the page\n    console.log(`Opening registration page: ${this.url}`);\n    return Promise.resolve();\n  }\n  \n  async fillForm(userData) {\n    this.userData = { ...this.userData, ...userData };\n    console.log(`Filling form with: ${JSON.stringify(userData)}`);\n    return Promise.resolve();\n  }\n  \n  async submit() {\n    console.log(`Submitting form with: ${JSON.stringify(this.userData)}`);\n    // Simulate form submission\n    if (this.userData.email && !this.userData.email.includes('@')) {\n      throw new Error('Invalid email format');\n    }\n    return Promise.resolve();\n  }\n  \n  async getWelcomeMessage() {\n    return 'Welcome to our application, ' + this.userData.name + '!';\n  }\n  \n  async getEmailError() {\n    return 'Please enter a valid email address';\n  }\n  \n  async getCurrentUrl() {\n    return this.url;\n  }\n  \n  async getPageContent() {\n    return 'Registration page content';\n  }\n}\n\n// features/shopping-cart.feature - Another BDD feature example\n/*\nFeature: Shopping Cart\n  As a customer\n  I want to manage items in my shopping cart\n  So that I can purchase products\n\n  Scenario: Add item to empty cart\n    Given I have an empty shopping cart\n    When I add a product to the cart\n      | productName | price |\n      | Laptop      | 999.99|\n    Then the cart should contain 1 item\n    And the cart total should be $999.99\n\n  Scenario: Remove item from cart\n    Given I have a shopping cart with items\n      | productName | price | quantity |\n      | Laptop      | 999.99| 1        |\n      | Mouse       | 29.99 | 2        |\n    When I remove the Laptop from the cart\n    Then the cart should contain 1 item\n    And the cart total should be $59.98\n*/\n\n// step-definitions/shopping-cart.steps.js - Shopping cart step definitions\nGiven('I have an empty shopping cart', function() {\n  this.cart = [];\n  this.total = 0;\n});\n\nGiven('I have a shopping cart with items', function(dataTable) {\n  this.cart = dataTable.hashes().map(item => ({\n    ...item,\n    price: parseFloat(item.price),\n    quantity: parseInt(item.quantity)\n  }));\n  \n  this.total = this.cart.reduce((sum, item) => \n    sum + (item.price * item.quantity), 0\n  );\n});\n\nWhen('I add a product to the cart', function(dataTable) {\n  const product = dataTable.rowsHash();\n  this.cart.push({\n    productName: product.productName,\n    price: parseFloat(product.price),\n    quantity: 1\n  });\n  \n  this.total += parseFloat(product.price);\n});\n\nWhen('I remove the {string} from the cart', function(productName) {\n  const itemIndex = this.cart.findIndex(item => item.productName === productName);\n  if (itemIndex !== -1) {\n    const removedItem = this.cart.splice(itemIndex, 1)[0];\n    this.total -= (removedItem.price * removedItem.quantity);\n  }\n});\n\nThen('the cart should contain {int} item(s)', function(expectedCount) {\n  const actualCount = this.cart.reduce((sum, item) => sum + item.quantity, 0);\n  expect(actualCount).to.equal(expectedCount);\n});\n\nThen('the cart total should be ${float}', function(expectedTotal) {\n  expect(this.total).to.equal(expectedTotal);\n});",
      "explanation": "This example demonstrates Behavior-Driven Development practices including:\n\n1. **Gherkin Feature Files**: User registration and shopping cart features with scenarios\n2. **Given-When-Then Structure**: Clear scenario descriptions following BDD patterns\n3. **Step Definitions**: JavaScript implementations that connect scenarios to code\n4. **Data Tables**: Using tabular data in scenarios for multiple test cases\n5. **Scenario Outlines**: Parameterized scenarios for testing multiple values\n6. **Page Objects**: Abstraction layer for UI interactions\n\nKey concepts illustrated:\n- BDD feature file structure\n- Step definition implementation\n- Data table usage\n- Scenario parameterization\n- Page object pattern\n- Business-readable specifications\n\nThe examples show:\n- User registration scenarios with validation\n- Shopping cart management scenarios\n- Data-driven testing with tables\n- Reusable step definitions\n- Clear business language in scenarios",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Writing overly technical scenarios that business stakeholders can't understand",
        "solution": "Use business language and focus on behavior rather than implementation details in Gherkin scenarios",
        "severity": "high"
      },
      {
        "mistake": "Creating too many implementation details in step definitions making them brittle",
        "solution": "Keep step definitions focused and reusable, using page objects to abstract UI interactions",
        "severity": "high"
      },
      {
        "mistake": "Not involving business stakeholders in the BDD process",
        "solution": "Collaborate with business analysts and stakeholders during scenario creation to ensure requirements alignment",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement BDD for a User Management Feature",
        "description": "Create BDD specifications and step definitions for a user management system.",
        "checkpoints": [
          "Write Gherkin feature files with clear Given-When-Then scenarios",
          "Implement step definitions that translate business language to code",
          "Use data tables for parameterized testing scenarios",
          "Apply scenario outlines for testing multiple values",
          "Collaborate with stakeholders to validate scenario accuracy"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-13"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Advanced",
    "tags": [
      "BDD",
      "Gherkin",
      "Cucumber",
      "Behavior-Driven Development",
      "Scenarios"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 13,
    "moduleSlug": "testing-fundamentals",
    "title": "Performance Testing Fundamentals",
    "order": 13,
    "objectives": [
      "Plan and execute different types of performance tests (load, stress, spike, endurance)",
      "Analyze performance test results to identify bottlenecks and performance issues",
      "Use performance testing tools like Artillery, k6, or Apache JMeter effectively",
      "Establish performance baselines and service level agreements (SLAs)"
    ],
    "intro": "Performance testing is a critical practice that evaluates how a system performs under various conditions, ensuring applications meet performance requirements and provide a good user experience. Unlike functional testing that verifies correctness, performance testing focuses on speed, stability, and scalability under different load conditions.\n\nThere are several types of performance tests, each serving different purposes in the testing strategy. Load testing verifies system behavior under expected normal and peak load conditions, ensuring response times and throughput meet requirements. Stress testing pushes the system beyond normal limits to identify breaking points and failure modes. Spike testing evaluates how the system handles sudden, dramatic increases in load. Endurance testing (soak testing) runs the system under sustained load for extended periods to identify memory leaks and resource exhaustion issues.\n\nEffective performance testing requires careful planning and execution, including defining realistic test scenarios, creating appropriate test data, and simulating realistic user behavior. Test environments should closely mirror production environments in terms of hardware, network conditions, and data volumes to ensure accurate results. Proper monitoring and metrics collection during tests provide insights into system behavior and help identify performance bottlenecks.\n\nPerformance test analysis involves examining various metrics such as response times, throughput, error rates, and resource utilization. Establishing performance baselines and service level agreements (SLAs) provides clear criteria for evaluating system performance. Tools like Artillery, k6, and Apache JMeter offer different capabilities for creating and executing performance tests, from simple load tests to complex scenarios with realistic user behavior simulation.\n\nIn this lesson, you'll learn to plan and execute different types of performance tests, analyze results to identify bottlenecks, use performance testing tools effectively, and establish performance baselines and SLAs for your applications.",
    "code": {
      "example": "// performance-test.js - Performance testing with k6\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate, Trend } from 'k6/metrics';\n\n// Custom metrics\nconst errorRate = new Rate('errors');\nconst responseTime = new Trend('response_time');\n\n// Test configuration\nexport const options = {\n  // Ramp up to 100 virtual users over 30 seconds\n  stages: [\n    { duration: '30s', target: 100 },  // Ramp up\n    { duration: '1m', target: 100 },   // Stay at 100 users\n    { duration: '30s', target: 0 },    // Ramp down\n  ],\n  \n  // Configure scenarios\n  scenarios: {\n    constant_load: {\n      executor: 'constant-vus',\n      vus: 50,\n      duration: '2m',\n    },\n  },\n  \n  // Configure thresholds\n  thresholds: {\n    'http_req_duration': ['p(95)<500'], // 95% of requests should be below 500ms\n    'errors': ['rate<0.1'],             // Error rate should be less than 10%\n    'response_time': ['p(99)<1000'],    // 99% of response times under 1s\n  },\n};\n\n// Test data\nconst users = [\n  { username: 'user1', password: 'password1' },\n  { username: 'user2', password: 'password2' },\n  // ... more test users\n];\n\n// Main test function\nexport default function() {\n  // Simulate user thinking time\n  sleep(Math.random() * 3);\n  \n  // Random user for this iteration\n  const user = users[Math.floor(Math.random() * users.length)];\n  \n  // Login request\n  const loginPayload = JSON.stringify({\n    username: user.username,\n    password: user.password,\n  });\n  \n  const loginParams = {\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  };\n  \n  const loginResponse = http.post('https://api.example.com/login', loginPayload, loginParams);\n  \n  // Record metrics\n  responseTime.add(loginResponse.timings.duration);\n  errorRate.add(loginResponse.status >= 400);\n  \n  // Check response\n  check(loginResponse, {\n    'login status is 200': (r) => r.status === 200,\n    'login response has token': (r) => r.json().hasOwnProperty('token'),\n  });\n  \n  // Get auth token\n  const token = loginResponse.json('token');\n  \n  // Make authenticated requests\n  const authHeaders = {\n    headers: {\n      'Authorization': `Bearer ${token}`,\n      'Content-Type': 'application/json',\n    },\n  };\n  \n  // Get user profile\n  const profileResponse = http.get('https://api.example.com/profile', authHeaders);\n  responseTime.add(profileResponse.timings.duration);\n  errorRate.add(profileResponse.status >= 400);\n  \n  check(profileResponse, {\n    'profile status is 200': (r) => r.status === 200,\n    'profile has user data': (r) => r.json().hasOwnProperty('name'),\n  });\n  \n  // Get products\n  const productsResponse = http.get('https://api.example.com/products', authHeaders);\n  responseTime.add(productsResponse.timings.duration);\n  errorRate.add(productsResponse.status >= 400);\n  \n  check(productsResponse, {\n    'products status is 200': (r) => r.status === 200,\n    'products response is array': (r) => Array.isArray(r.json()),\n  });\n  \n  // Create order (POST request)\n  const orderPayload = JSON.stringify({\n    productId: Math.floor(Math.random() * 100) + 1,\n    quantity: Math.floor(Math.random() * 5) + 1,\n  });\n  \n  const orderResponse = http.post('https://api.example.com/orders', orderPayload, authHeaders);\n  responseTime.add(orderResponse.timings.duration);\n  errorRate.add(orderResponse.status >= 400);\n  \n  check(orderResponse, {\n    'order status is 201': (r) => r.status === 201,\n    'order has ID': (r) => r.json().hasOwnProperty('id'),\n  });\n  \n  // Simulate user thinking time\n  sleep(Math.random() * 2);\n}\n\n// Handle test setup\nexport function setup() {\n  console.log('Starting performance test...');\n  return { startTime: new Date().toISOString() };\n}\n\n// Handle test teardown\nexport function teardown(data) {\n  console.log(`Test completed. Started at: ${data.startTime}`);\n}\n\n// Handle test thresholds\nexport function handleSummary(data) {\n  return {\n    'stdout': JSON.stringify(data, null, 2),\n    'summary.json': JSON.stringify(data),\n    'summary.html': \n      `<html>\n        <head>\n          <title>Performance Test Results</title>\n        </head>\n        <body>\n          <h1>Performance Test Results</h1>\n          <p>Total requests: ${data.metrics.http_reqs ? data.metrics.http_reqs.values.count : 0}</p>\n          <p>Average response time: ${data.metrics.http_req_duration ? data.metrics.http_req_duration.values.avg.toFixed(2) : 0}ms</p>\n          <p>Error rate: ${data.metrics.errors ? (data.metrics.errors.values.rate * 100).toFixed(2) : 0}%</p>\n        </body>\n      </html>`,\n  };\n}\n\n// stress-test.js - Stress testing example\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  // Stress test with increasing load\n  stages: [\n    { duration: '1m', target: 100 },   // Normal load\n    { duration: '1m', target: 200 },   // Double load\n    { duration: '1m', target: 500 },   // High load\n    { duration: '30s', target: 1000 }, // Spike\n    { duration: '30s', target: 0 },    // Ramp down\n  ],\n  \n  thresholds: {\n    'http_req_duration': ['p(95)<1000'], // 95% under 1s\n    'http_req_failed': ['rate<0.05'],    // Less than 5% failure rate\n  },\n};\n\nexport default function() {\n  // Simulate realistic user behavior\n  const endpoints = [\n    'https://api.example.com/products',\n    'https://api.example.com/categories',\n    'https://api.example.com/users/profile',\n  ];\n  \n  // Random endpoint\n  const url = endpoints[Math.floor(Math.random() * endpoints.length)];\n  \n  const res = http.get(url);\n  \n  check(res, {\n    'status is 200': (r) => r.status === 200,\n    'response time < 2s': (r) => r.timings.duration < 2000,\n  });\n  \n  sleep(Math.random() * 3);\n}\n\n// endurance-test.js - Endurance testing example\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  // Run for 1 hour with 50 virtual users\n  vus: 50,\n  duration: '1h',\n  \n  thresholds: {\n    'http_req_duration': ['p(95)<500'],\n    'http_req_failed': ['rate<0.01'],\n    'checks': ['rate>0.99'],\n  },\n};\n\nexport default function() {\n  // User journey simulation\n  const baseUrl = 'https://api.example.com';\n  \n  // 1. Browse products\n  const productsRes = http.get(`${baseUrl}/products`);\n  check(productsRes, { 'products status is 200': (r) => r.status === 200 });\n  \n  // 2. View product details\n  const productId = Math.floor(Math.random() * 1000) + 1;\n  const productRes = http.get(`${baseUrl}/products/${productId}`);\n  check(productRes, { 'product status is 200': (r) => r.status === 200 });\n  \n  // 3. Add to cart\n  const cartRes = http.post(`${baseUrl}/cart`, JSON.stringify({\n    productId: productId,\n    quantity: 1\n  }), {\n    headers: { 'Content-Type': 'application/json' }\n  });\n  check(cartRes, { 'cart status is 200': (r) => r.status === 200 });\n  \n  // Simulate user thinking time\n  sleep(Math.random() * 5);\n}",
      "explanation": "This example demonstrates performance testing fundamentals using k6 including:\n\n1. **Load Testing**: Configuring virtual users and test stages\n2. **Stress Testing**: Pushing system beyond normal limits\n3. **Endurance Testing**: Long-running tests to identify resource issues\n4. **Custom Metrics**: Tracking response times and error rates\n5. **Thresholds**: Defining pass/fail criteria for performance\n6. **Realistic User Simulation**: Modeling actual user behavior\n\nKey concepts illustrated:\n- Performance test configuration\n- Metric collection and analysis\n- Threshold definition\n- User behavior simulation\n- Test result reporting\n- Different performance test types\n\nThe examples show:\n- Load test with ramp-up and ramp-down\n- Stress test with increasing load\n- Endurance test for long-term stability\n- Custom metric tracking\n- Response validation\n- Result reporting in multiple formats",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Running performance tests in environments that don't match production conditions",
        "solution": "Use environments that closely mirror production in terms of hardware, network, and data to ensure accurate results",
        "severity": "high"
      },
      {
        "mistake": "Not establishing clear performance criteria and SLAs before testing",
        "solution": "Define specific performance goals and thresholds before conducting tests to enable objective evaluation",
        "severity": "high"
      },
      {
        "mistake": "Testing only under ideal conditions rather than realistic user scenarios",
        "solution": "Create tests that simulate real user behavior including think time, varied workflows, and concurrent users",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement Comprehensive Performance Testing Suite",
        "description": "Create performance tests for a web application including load, stress, and endurance tests.",
        "checkpoints": [
          "Design load tests that simulate expected user traffic patterns",
          "Implement stress tests to identify system breaking points",
          "Create endurance tests to detect memory leaks and resource issues",
          "Configure custom metrics and thresholds for performance evaluation",
          "Analyze test results to identify bottlenecks and performance issues"
        ]
      }
    ],
    "next": [
      "testing-fundamentals-lesson-14"
    ],
    "estimatedMinutes": 90,
    "difficulty": "Advanced",
    "tags": [
      "Performance Testing",
      "Load Testing",
      "k6",
      "Stress Testing",
      "Metrics"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  },
  {
    "id": 14,
    "moduleSlug": "testing-fundamentals",
    "title": "Test Coverage Analysis",
    "order": 14,
    "objectives": [
      "Measure and interpret different types of code coverage metrics",
      "Use coverage tools effectively to identify untested code paths",
      "Set appropriate coverage targets and thresholds for different project types",
      "Analyze coverage reports to improve test suite quality and completeness"
    ],
    "intro": "Test coverage analysis is a measurement technique that determines how much of the source code is executed during testing. While high coverage doesn't guarantee good tests, it does provide valuable insights into which parts of the code have been exercised and which areas might be lacking test coverage. Understanding coverage metrics helps teams identify gaps in their test suites and make informed decisions about testing efforts.\n\nThere are several types of coverage metrics, each providing different insights into test completeness. Statement coverage measures the percentage of executable statements that have been executed. Branch coverage evaluates whether all possible branches (if/else, switch cases) have been taken. Function coverage tracks which functions have been called. Line coverage indicates which lines of code have been executed. Path coverage, the most comprehensive but complex metric, measures whether all possible execution paths through the code have been tested.\n\nEffective coverage analysis requires using appropriate tools that integrate with the development workflow and provide actionable insights. Popular tools include Istanbul/nyc for JavaScript, Coverage.py for Python, and built-in tools in IDEs and CI/CD platforms. These tools generate detailed reports that highlight uncovered code sections and provide metrics for different coverage types.\n\nSetting appropriate coverage targets is crucial for maintaining a balance between testing thoroughness and development efficiency. Different project types and risk levels may require different coverage thresholds. Critical systems might require 90%+ coverage, while less critical applications might target 70-80%. It's important to focus on meaningful coverage rather than just meeting arbitrary percentages, ensuring that important business logic and error paths are well-tested.\n\nCoverage analysis should be part of the continuous integration process, with reports generated automatically and made available to the development team. Regular analysis of coverage reports helps identify trends, coverage gaps, and areas where tests might be improved. Teams should use coverage data to guide testing efforts and ensure that new code is adequately tested before being merged.\n\nIn this lesson, you'll learn to measure and interpret different coverage metrics, use coverage tools effectively, set appropriate coverage targets, and analyze coverage reports to improve test quality.",
    "code": {
      "example": "// calculator.js - Code to be tested\n\nclass Calculator {\n  add(a, b) {\n    return a + b;\n  }\n  \n  subtract(a, b) {\n    return a - b;\n  }\n  \n  multiply(a, b) {\n    if (a === 0 || b === 0) {\n      return 0;\n    }\n    return a * b;\n  }\n  \n  divide(a, b) {\n    if (b === 0) {\n      throw new Error('Division by zero');\n    }\n    return a / b;\n  }\n  \n  factorial(n) {\n    if (n < 0) {\n      throw new Error('Factorial not defined for negative numbers');\n    }\n    if (n === 0 || n === 1) {\n      return 1;\n    }\n    \n    let result = 1;\n    for (let i = 2; i <= n; i++) {\n      result *= i;\n    }\n    return result;\n  }\n  \n  isPrime(num) {\n    if (num <= 1) {\n      return false;\n    }\n    if (num <= 3) {\n      return true;\n    }\n    if (num % 2 === 0 || num % 3 === 0) {\n      return false;\n    }\n    \n    for (let i = 5; i * i <= num; i += 6) {\n      if (num % i === 0 || num % (i + 2) === 0) {\n        return false;\n      }\n    }\n    return true;\n  }\n  \n  // Complex method with multiple branches\n  calculateDiscount(price, customerType, isLoyalCustomer) {\n    let discount = 0;\n    \n    if (price > 1000) {\n      if (customerType === 'premium') {\n        discount = 0.2;\n      } else if (customerType === 'standard') {\n        discount = 0.1;\n      } else {\n        discount = 0.05;\n      }\n      \n      if (isLoyalCustomer) {\n        discount += 0.05;\n      }\n    } else if (price > 500) {\n      discount = customerType === 'premium' ? 0.1 : 0.05;\n    } else {\n      discount = 0;\n    }\n    \n    return price * (1 - discount);\n  }\n}\n\nmodule.exports = Calculator;\n\n// calculator.test.js - Tests with coverage analysis\nconst Calculator = require('./calculator');\n\ndescribe('Calculator', () => {\n  let calculator;\n  \n  beforeEach(() => {\n    calculator = new Calculator();\n  });\n  \n  test('should add two numbers correctly', () => {\n    expect(calculator.add(2, 3)).toBe(5);\n    expect(calculator.add(-1, 1)).toBe(0);\n  });\n  \n  test('should subtract two numbers correctly', () => {\n    expect(calculator.subtract(5, 3)).toBe(2);\n    expect(calculator.subtract(0, 5)).toBe(-5);\n  });\n  \n  test('should multiply two numbers correctly', () => {\n    expect(calculator.multiply(3, 4)).toBe(12);\n    expect(calculator.multiply(0, 5)).toBe(0);\n    expect(calculator.multiply(-2, 3)).toBe(-6);\n  });\n  \n  test('should divide two numbers correctly', () => {\n    expect(calculator.divide(10, 2)).toBe(5);\n    expect(calculator.divide(7, 2)).toBe(3.5);\n  });\n  \n  test('should throw error when dividing by zero', () => {\n    expect(() => calculator.divide(10, 0)).toThrow('Division by zero');\n  });\n  \n  test('should calculate factorial correctly', () => {\n    expect(calculator.factorial(0)).toBe(1);\n    expect(calculator.factorial(1)).toBe(1);\n    expect(calculator.factorial(5)).toBe(120);\n  });\n  \n  test('should throw error for negative factorial', () => {\n    expect(() => calculator.factorial(-1)).toThrow('Factorial not defined for negative numbers');\n  });\n  \n  test('should determine if number is prime', () => {\n    expect(calculator.isPrime(2)).toBe(true);\n    expect(calculator.isPrime(17)).toBe(true);\n    expect(calculator.isPrime(4)).toBe(false);\n    expect(calculator.isPrime(1)).toBe(false);\n  });\n  \n  // Note: We're missing tests for calculateDiscount method\n  // This will show up in coverage reports\n});\n\n// complex-business-logic.js - More complex code for coverage analysis\n\nclass OrderProcessor {\n  processOrder(order, customer) {\n    // Validate order\n    if (!order || !order.items || order.items.length === 0) {\n      throw new Error('Invalid order');\n    }\n    \n    // Validate customer\n    if (!customer) {\n      throw new Error('Customer required');\n    }\n    \n    // Calculate subtotal\n    const subtotal = order.items.reduce((sum, item) => {\n      return sum + (item.price * item.quantity);\n    }, 0);\n    \n    // Apply discount based on customer type and order value\n    let discount = 0;\n    \n    if (customer.type === 'premium') {\n      if (subtotal > 1000) {\n        discount = 0.2;\n      } else if (subtotal > 500) {\n        discount = 0.15;\n      } else {\n        discount = 0.1;\n      }\n    } else if (customer.type === 'standard') {\n      if (subtotal > 1000) {\n        discount = 0.1;\n      } else if (subtotal > 500) {\n        discount = 0.05;\n      }\n    }\n    \n    // Apply loyalty discount\n    if (customer.isLoyal && subtotal > 200) {\n      discount += 0.05;\n    }\n    \n    // Apply seasonal discount (complex logic)\n    const currentDate = new Date();\n    const month = currentDate.getMonth();\n    \n    if (month === 11) { // December\n      discount += 0.1;\n    } else if (month === 9) { // October\n      if (currentDate.getDate() <= 7) { // First week\n        discount += 0.05;\n      }\n    }\n    \n    // Ensure discount doesn't exceed 50%\n    discount = Math.min(discount, 0.5);\n    \n    // Calculate final amount\n    const discountAmount = subtotal * discount;\n    const total = subtotal - discountAmount;\n    \n    // Apply tax\n    const taxRate = this.getTaxRate(customer.address);\n    const taxAmount = total * taxRate;\n    const finalTotal = total + taxAmount;\n    \n    return {\n      orderId: order.id,\n      subtotal: parseFloat(subtotal.toFixed(2)),\n      discount: parseFloat(discountAmount.toFixed(2)),\n      tax: parseFloat(taxAmount.toFixed(2)),\n      total: parseFloat(finalTotal.toFixed(2)),\n      discountPercentage: parseFloat((discount * 100).toFixed(2))\n    };\n  }\n  \n  getTaxRate(address) {\n    const state = address.state?.toUpperCase();\n    \n    switch (state) {\n      case 'NY':\n        return 0.08875;\n      case 'CA':\n        return 0.0725;\n      case 'TX':\n        return 0.0625;\n      case 'FL':\n        return 0.06;\n      default:\n        return 0.05;\n    }\n  }\n  \n  validatePayment(payment) {\n    if (!payment) {\n      throw new Error('Payment information required');\n    }\n    \n    if (!payment.method) {\n      throw new Error('Payment method required');\n    }\n    \n    switch (payment.method) {\n      case 'credit_card':\n        if (!payment.cardNumber || !payment.expiry || !payment.cvv) {\n          throw new Error('Credit card information incomplete');\n        }\n        // Validate card number format\n        if (!/^\\d{16}$/.test(payment.cardNumber)) {\n          throw new Error('Invalid card number format');\n        }\n        break;\n      \n      case 'paypal':\n        if (!payment.email) {\n          throw new Error('PayPal email required');\n        }\n        // Validate email format\n        if (!/^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test(payment.email)) {\n          throw new Error('Invalid email format');\n        }\n        break;\n      \n      case 'bank_transfer':\n        if (!payment.accountNumber || !payment.routingNumber) {\n          throw new Error('Bank account information required');\n        }\n        break;\n      \n      default:\n        throw new Error(`Unsupported payment method: ${payment.method}`);\n    }\n    \n    return true;\n  }\n}\n\nmodule.exports = OrderProcessor;\n\n// complex-business-logic.test.js - Tests for complex logic\nconst OrderProcessor = require('./complex-business-logic');\n\ndescribe('OrderProcessor', () => {\n  let processor;\n  \n  beforeEach(() => {\n    processor = new OrderProcessor();\n  });\n  \n  test('should process order with premium customer discount', () => {\n    const order = {\n      id: '123',\n      items: [\n        { price: 600, quantity: 1 },\n        { price: 400, quantity: 1 }\n      ]\n    };\n    \n    const customer = {\n      type: 'premium',\n      isLoyal: true,\n      address: { state: 'NY' }\n    };\n    \n    const result = processor.processOrder(order, customer);\n    \n    expect(result.subtotal).toBe(1000);\n    expect(result.discountPercentage).toBe(25); // 20% premium + 5% loyalty\n    expect(result.total).toBeCloseTo(814.06); // 1000 - 250 discount + tax\n  });\n  \n  test('should validate credit card payment', () => {\n    const payment = {\n      method: 'credit_card',\n      cardNumber: '1234567890123456',\n      expiry: '12/25',\n      cvv: '123'\n    };\n    \n    expect(processor.validatePayment(payment)).toBe(true);\n  });\n  \n  test('should reject invalid credit card number', () => {\n    const payment = {\n      method: 'credit_card',\n      cardNumber: '12345', // Invalid format\n      expiry: '12/25',\n      cvv: '123'\n    };\n    \n    expect(() => processor.validatePayment(payment))\n      .toThrow('Invalid card number format');\n  });\n  \n  // Note: Missing tests for many branches and edge cases\n  // Coverage reports will highlight these gaps\n});",
      "explanation": "This example demonstrates test coverage analysis including:\n\n1. **Code Coverage Measurement**: Calculator and OrderProcessor classes with various complexity levels\n2. **Incomplete Test Coverage**: Tests that don't cover all code paths, showing real-world scenarios\n3. **Branch Coverage Gaps**: Complex conditional logic with untested branches\n4. **Edge Case Coverage**: Error conditions and boundary values\n\nKey concepts illustrated:\n- Statement coverage measurement\n- Branch coverage analysis\n- Function coverage tracking\n- Complex business logic coverage\n- Coverage gap identification\n\nThe examples show:\n- Basic calculator operations with full coverage\n- Complex business logic with partial coverage\n- Multiple conditional branches\n- Error handling scenarios\n- Edge case testing\n- Coverage reporting needs",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Focusing solely on coverage percentage rather than meaningful test quality",
        "solution": "Use coverage as a guide to identify untested code, but prioritize testing important business logic and error paths over meeting arbitrary percentages",
        "severity": "high"
      },
      {
        "mistake": "Not integrating coverage analysis into the CI/CD pipeline",
        "solution": "Automate coverage reporting in continuous integration to ensure coverage is monitored consistently",
        "severity": "high"
      },
      {
        "mistake": "Setting unrealistic 100% coverage targets leading to superficial tests",
        "solution": "Set appropriate coverage targets based on project risk levels and focus on critical code paths rather than absolute percentages",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Implement Comprehensive Coverage Analysis",
        "description": "Set up coverage analysis for a JavaScript application and improve test suite based on coverage reports.",
        "checkpoints": [
          "Configure coverage tools (Istanbul/nyc) for a JavaScript project",
          "Generate coverage reports showing statement, branch, and function coverage",
          "Identify uncovered code paths and prioritize them for testing",
          "Improve test suite to increase meaningful coverage",
          "Set up automated coverage reporting in CI/CD pipeline"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 90,
    "difficulty": "Advanced",
    "tags": [
      "Test Coverage",
      "Code Coverage",
      "Istanbul",
      "Metrics",
      "Analysis"
    ],
    "lastUpdated": "2025-10-09T10:00:00.000Z",
    "version": "1.0.0",
    "sources": []
  }
]
